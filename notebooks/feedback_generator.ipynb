{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Repository setup for portable, repo-relative paths\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "def _find_repo_root(start: Path | None = None) -> Path:\n",
    "    start = (start or Path.cwd()).resolve()\n",
    "    for candidate in [start, *start.parents]:\n",
    "        if (candidate / \"pyproject.toml\").exists():\n",
    "            return candidate\n",
    "    return start\n",
    "\n",
    "REPO_ROOT = _find_repo_root()\n",
    "if str(REPO_ROOT / \"src\") not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT / \"src\"))\n",
    "\n",
    "from dx_chat_entropy.paths import get_paths\n",
    "PATHS = get_paths(REPO_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback Generator \n",
    "\n",
    "- Draft: Feb 28, 2025; Update Mar 3, 2025.\n",
    "- Brian Locke MD MSCI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Framing of Errors\n",
    "\n",
    "Learners can make two types of errors:\n",
    "\n",
    "\t1.\tFailing to gather key information.\n",
    "\t2.\tMisinterpreting the meaning of collected data.\n",
    "\n",
    "In practice these processes —information gathering and reasoning— are interconnected, as reasoning guides the questions asked during an encounter.  However, separating the processes for feedback may help learners pinpoint areas for improvement. For now, feedback is only provided at the end, so we are limited to evaluating both processes based on the completed interview.\n",
    "\n",
    "### Framing of Feedback \n",
    "\n",
    "For information gathering: \n",
    "\n",
    "- We want to give positive feedback: what were the pieces of information that the learners gathered correctly\n",
    "- We want to higlight areas for improvement\n",
    "\t- For information gathering, this might involve the pieces of information from *this case* that could have \n",
    "\t- For reasoning, this might involve our algorithm giving an estimate of how the probabilities ought to have been combined, given the information that was collected\n",
    "\n",
    "### Goals\n",
    "\n",
    "To guide positive feedback we want: \n",
    "- What are the strongest features that increase the odds of CREST\n",
    "- What are the strongest features that increase the odds of CREST that are present in this particular case? \n",
    "\n",
    "To guide areas for improvement we want: \n",
    "- What are the strongest features that Increase the odds of CREST (vs each entry that the learner puts in their differential diagnosis)\n",
    "- What are the strongest features that Increase the odds of CREST (vs each entry that the learner puts in their differential diagnosis) that are present in this particular case? \n",
    "- Given the information that was gathered what should the ranked differential diagnosis have been? \n",
    "- Ideally, we would also want to correct the reasoning that the learner gives (which would require them to explain their reasoning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Literal, Dict, List\n",
    "\n",
    "load_dotenv()  # looks for a .env file in the current dir by default- should contain a line \"OPENAI_API_KEY=yourkey\"\n",
    "#print(os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "ModelRunType = Literal[\"4o-mini\", \"4o\", \"o3-mini\"]\n",
    "model_run: ModelRunType = \"o3-mini\"  # Allowed 1 of: '4o-mini', '4o', or 'o3-mini'\n",
    "\n",
    "only_overall = True # If True, only runs the script for the Subjective/Historical data (not objective, testing, and not subdivided) \n",
    "\n",
    "current_date = datetime.today().strftime('%Y-%m-%d')\n",
    "output_directory = os.path.join(PATHS.artifacts, \"feedback_sheets\", f\"{current_date}_{model_run}_feedback_sheets\")\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "    print(f\"Directory '{output_directory}' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_response(text):\n",
    "    \"\"\"Remove leading/trailing whitespace and code fences if present\"\"\"\n",
    "    text = text.strip()\n",
    "    if text.startswith(\"```json\"):\n",
    "        text = text[len(\"```json\"):].strip()\n",
    "    if text.endswith(\"```\"):\n",
    "        text = text[:-len(\"```\")].strip()\n",
    "    return text\n",
    "\n",
    "def call_openai_api(prompt, model_type):\n",
    "    \"\"\"\n",
    "    Function to call OpenAI API\n",
    "    Assume calling a model that supports structured response\n",
    "    \"\"\"\n",
    "    client = openai.OpenAI()  # Create a client instance\n",
    "    system_prompt = \"You are a knowledgeable medical reasoning AI- an expert diagnostician. \\\n",
    "                You must follow these rules: \\\n",
    "                1. You identify the strongest clinical findings for or against a given diagnosis. \\\n",
    "                2. Focus on only one category of evidence at a time. \\\n",
    "                3. Provide output in valid JSON with no extra commentary. \\\n",
    "                4. Comply with the user instructions below.\"\n",
    "\n",
    "    if model_type == \"o3-mini\": \n",
    "        response = client.chat.completions.create(\n",
    "        model=\"o3-mini-2025-01-31\",\n",
    "        messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt\n",
    "        }, \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }], \n",
    "        reasoning_effort=\"high\"\n",
    "    )\n",
    "    elif model_type == \"4o\":\n",
    "        response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-2024-08-06\",\n",
    "        messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt\n",
    "        }, \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }],\n",
    "        temperature=0\n",
    "    )\n",
    "    else: \n",
    "        response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini-2024-07-18\",\n",
    "        messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt\n",
    "        }, \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    # Log the entire raw API response for debugging.\n",
    "    print(\"Raw API Response:\", response)\n",
    "\n",
    "    raw_content = response.choices[0].message.content\n",
    "    content = clean_response(raw_content)\n",
    "    if not content.strip():\n",
    "        print(\"Received an empty response\")\n",
    "    else:\n",
    "        try:\n",
    "            parsed_response = json.loads(content)\n",
    "        except Exception as e:\n",
    "            print(\"Error parsing JSON:\", e)\n",
    "            print(\"Response content:\", content)\n",
    "    return json.loads(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Gathering Feedback\n",
    "\n",
    "#### Two different types of likelihood ratios\n",
    "\n",
    "The likelihood ratio represents the relative information in favor of 1 hypothesis and against another. \n",
    "\n",
    "In the usual positive and negative likelihood ratios, the two hypothesis are: \n",
    "- H0 = Disease A is present\n",
    "- H1 = Disease A is not present\n",
    "And therefore, the LR summarizes the evidence for the disease and against *everything else*\n",
    "\n",
    "However, if you are reasoning about a constraint set of diagnoses - say, disease A and disease B - and you know that it's 1 but not both of the two diseases that explains the presentation... then the information can be summarized by whats been called a \"differential\" likelihood ratio: \n",
    "- H0 = Disease A is present (and disease B is not present) \n",
    "- H1 = Disease B is present (and disease A is not present) \n",
    "And then the LR_differential summarizes the amount that a piece of evidence supports Disease A over Disease B. \n",
    "(from https://academic.oup.com/book/31795/chapter/266181309?login=false)\n",
    "\n",
    "Ample data exists on overall likelihood ratios (however, it should be noted that for an estimate of an overall LR to apply, both the spectrum of Disease A and the spectrum of not disease A cases must be similar - see https://pmc.ncbi.nlm.nih.gov/articles/PMC4916916/ )\n",
    "\n",
    "Thus, \n",
    "- LR_overall might be most important in summarizing which pieces of information are helpful in supporting a particular diagnosis\n",
    "- LR_differential might be particularly relevant when \n",
    "\t- either deliberating between a few remaining entries on the differential (e.g. reasoning by elimination)\n",
    "\t- understanding why a particular proposed diagnosis is incorrect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "# TODO: for production, extract these automatically from transcripts/directory\n",
    "correct_diagnosis = \"CREST syndrome with Type 2 Achalasia\"\n",
    "\n",
    "# The list of alternative diagnoses for the LLM to evaluate evidence against\n",
    "differential_diagnoses = [\n",
    "    \"CREST syndrome with Type 2 Achalasia\",\n",
    "    \"Scleroderma\",\n",
    "    \"Esophageal stricture\",\n",
    "    \"Food impaction\",\n",
    "    \"Mixed Connective Tissue Disease\",\n",
    "    \"Achalasia (type 1)\",\n",
    "    \"Eosinophilic esophagitis\",\n",
    "    \"Acute Coronary Syndrome\",\n",
    "    \"Stable Angina\",\n",
    "    \"Esophageal spasm a.k.a Jackhammer Esophagus\",\n",
    "    \"Esophageal adenocarcinoma\",\n",
    "    \"Esophageal squamous cell carcinoma\",\n",
    "    \"Musculoskeletal chest pain\",\n",
    "    \"GERD\",\n",
    "    \"Zenker's diverticulum\",\n",
    "    \"Polymyositis\",\n",
    "    \"Dermatomyositis\",\n",
    "    \"Chagas Disease\",\n",
    "    \"Anxiety\",\n",
    "    \"Arrhythmia\",\n",
    "    \"Aortic dissection\",\n",
    "    \"Pericarditis\",\n",
    "    \"Extrinsic compressing mass on esophagus\",\n",
    "    \"Rheumatoid Athritis\",\n",
    "    \"Sarcoidosis\",\n",
    "    \"Pill esophagitis\",\n",
    "    \"Myasthenia gravis\",\n",
    "    \"Gastroparesis\" \n",
    "]\n",
    "\n",
    "CategoryKey = Literal[\"hpi\", \"hist\", \"soc\", \"obj\", \"test\", \"subjective-and-historical\"]\n",
    "\n",
    "categories_of_info_dict: Dict[CategoryKey, str] = {\n",
    "    \"hpi\": \"History of Present Illness (the description from the onset of symptoms up to and including the patient's present experience)\",\n",
    "    \"hist\": \"Past Medical History, current medications, and Past Surgical History (a description of previously established diagnoses, as well as there treatments like medications and therapeutic procedures)\",\n",
    "    \"soc\": \"Social History, Health Behaviors, and Family History (a description of the social - e.g. does the patient participate in activities that increase risk? - and genetic - e.g. does it run in the family? - context of disease\",\n",
    "    \"obj\": \"Vitals and Physical Exam (a description of the objective measurements and findings a doctor would expect to see with a thorough physical exam)\",\n",
    "    \"test\": \"Test Results (labs, imaging, procedures, etc.)\", \n",
    "    \"subjective-and-historical\": \"\"\"Any subjective or historical information about the patient’s condition, including:\n",
    "\t1.\tHistory of Present Illness (HPI): The narrative describing the onset of symptoms, their progression, and the patient’s current experience.\n",
    "\t2.\tPast Medical History (PMH): Previously diagnosed conditions and treatments (including medications).\n",
    "\t3.\tCurrent Medications: All medications the patient is currently taking.\n",
    "\t4.\tPast Surgical History (PSH): Previous surgical interventions and therapeutic procedures.\n",
    "\t5.\tSocial History & Health Behaviors: Lifestyle factors, social context, and risk-related activities.\n",
    "\t6.\tFamily History: Genetic predispositions and conditions that run in the family.\n",
    "\tDo not consider objective clinical data such as vital signs, physical exam findings, and test results (e.g., lab values, imaging reports, procedure outcomes).\n",
    "    \"\"\"\n",
    "    }\n",
    "\n",
    "# The particulars of this case contains \n",
    "# note, a couople of these are relevant to multiple categories, and there is sometimes some subtle differences between what each means (e.g. abodminal pain reported vs abdominal pauin on exam)\n",
    "hpi_details = [\n",
    "  {\"Pain relieved with regurgitation\": \"present\"},\n",
    "  {\"Raynauds phenomenon reported\": \"present\"},\n",
    "  {\"Telangiectasias reported\": \"present\"},\n",
    "  {\"Hand pain out of proportion to other joints\": \"present\"},\n",
    "  {\"Current heartburn\": \"present\"},\n",
    "  {\"Current reflux\": \"present\"},\n",
    "  {\"Long-standing heartburn (duration of years)\": \"present\"},\n",
    "  {\"Long-standing reflux (duration of years)\": \"present\"},\n",
    "  {\"Pain previously better with antacids\": \"absent\"},\n",
    "  {\"Antacids no longer providing relief\": \"present\"},\n",
    "  {\"Difficulty swallowing liquids\": \"present\"},\n",
    "  {\"Difficulty swallowing solids\": \"present\"},\n",
    "  {\"Non-progressive dysphagia: liquids throughout difficulty swallowing\": \"present\"},\n",
    "  {\"Weight loss reported\": \"present\"},\n",
    "  {\"Hoarse voice reported\": \"absent\"},\n",
    "  {\"Cough reported\": \"absent\"},\n",
    "  {\"Globus sensation\": \"absent\"},\n",
    "  {\"Epigastric pain or dyspepsia reported\": \"absent\"},\n",
    "  {\"Shortness of breath\": \"absent\"},\n",
    "  {\"Hand thickness reported\": \"absent\"},\n",
    "  {\"Finger ulcers reported\": \"absent\"},\n",
    "  {\"Weakness reported\": \"absent\"},\n",
    "  {\"Intermittent temporal pattern (not constant) of symptoms\": \"absent\"},\n",
    "  {\"Tightness (character of pain)\": \"present\"},\n",
    "  {\"duration of 3 months of increased frequency of chest pain\": \"absent\"},\n",
    "  {\"duration of 3 months of food getting stuck\": \"present\"},\n",
    "  {\"Onset of chest pain associated with eating food\": \"present\"},\n",
    "  {\"Exertion makes it worse (without clarifying within an hour of eating)\": \"absent\"},\n",
    "  {\"Exertion makes it worse for more than an hour after eating\": \"absent\"},\n",
    "  {\"Pain worse when lying down (positional)\": \"present\"},\n",
    "  {\"Pain when swallowing (aka odynophagia)\": \"present\"},\n",
    "  {\"Bloating with intermittent upper abdominal pain reported\": \"present\"},\n",
    "  {\"Reports pain location is behind sternum, middle of chest\": \"present\"},\n",
    "  {\"diaphoresis\": \"absent\"},\n",
    "  {\"decreased exercise over the last 3 months\": \"absent\"},\n",
    "  {\"onset of symptoms in the last 24 hours (not acute or hyperacute)\": \"absent\"},\n",
    "  {\"Radiation of pain to the back\": \"absent\"},\n",
    "  {\"Nausea and/or vomiting\": \"absent\"},\n",
    "  {\"Early satiety\": \"absent\"},\n",
    "  {\"Dry eye reported\": \"absent\"},\n",
    "  {\"Red eye reported\": \"absent\"},\n",
    "  {\"Neck masses or fullness reported\": \"absent\"},    \n",
    "  {\"Pleuritic character of the pain\": \"absent\"},\n",
    "  {\"Sharp character of the pain\": \"absent\"},\n",
    "  {\"Stabbing character of the pain\": \"absent\"},\n",
    "  {\"Pain is reproducible with arm movements\": \"absent\"},\n",
    "  {\"Spasmodic character of pain\": \"absent\"},\n",
    "  {\"Palpitations\": \"absent\"},\n",
    "  {\"Halitosis reported\": \"absent\"},\n",
    "  {\"Recent injuries reported\": \"absent\"},\n",
    "  {\"Vision changes reported\": \"absent\"},\n",
    "  {\"Multiple symmetric joints hurt\": \"present\"},\n",
    "  {\"Morning stiffness\": \"absent\"},\n",
    "  {\"Joint swelling reported\": \"absent\"},\n",
    "  {\"Enlargement of knuckles, finger deformities, or deviation of fingers reported\": \"absent\"}\n",
    "]\n",
    "\n",
    "hist_details = [\n",
    "    {\"Alcohol use disorder\": \"absent\"},\n",
    "    {\"Nicotine dependence\": \"absent\"},\n",
    "    {\"Prior treatment with radiation to the neck, arm, or jaw\": \"absent\"},\n",
    "    {\"Previously diagnosed Coronary Artery Disease\": \"absent\"},\n",
    "    {\"Prevopis;u doagmpsed Peripheral Artery Disease\": \"absent\"},\n",
    "    {\"Previously diagnosed Hyperlipidemia\": \"absent\"},\n",
    "    {\"prior myocardial infarction\": \"absent\"},\n",
    "    {\"type 2 diabetes\": \"absent\"},\n",
    "    {\"obesity\": \"absent\"},\n",
    "    {\"prior stroke\": \"absent\"},\n",
    "    {\"diagnosed hypertension\": \"present\"},\n",
    "    {\"recent medication changes\": \"absent\"},\n",
    "    {\"takes amlodipine\": \"present\"},\n",
    "    {\"Female\": \"present\"},\n",
    "    {\"middle age\": \"present\"},\n",
    "    {\"Environmental allergies\": \"absent\"},  \n",
    "    {\"Asthma\": \"absent\"},\n",
    "    {\"Eczema\": \"absent\"}\n",
    "]\n",
    "\n",
    "soc_details = [\n",
    "    {\"Family history of Rheumatoid Arthritis\": \"absent\"},\n",
    "    {\"Alcohol use\": \"absent\"},\n",
    "    {\"Current tobacco use\": \"absent\"},\n",
    "    {\"Prior tobacco use\": \"present\"},\n",
    "    {\"family history of myocardial infarction in father\": \"present\"},\n",
    "    {\"Recent social stress\": \"present\"},\n",
    "    {\"Recent Travel\": \"absent\"},\n",
    "    {\"Family history of cancer\": \"absent\"},\n",
    "    {\"Recent medical procedure\": \"absent\"},\n",
    "    {\"Gestational complications with prior pregnancy\": \"absent\"}    \n",
    "]\n",
    "\n",
    "obj_details = [\n",
    "  {\"Raynauds phenomennon on exam\": \"absent\"},\n",
    "  {\"Telangiectasias on exam\": \"present\"},\n",
    "  {\"Weight loss on vitals\": \"present\"},\n",
    "  {\"Hoarse voice observed\": \"absent\"},\n",
    "  {\"Cough observed\": \"absent\"},\n",
    "  {\"Epigastric pain on palpation\": \"absent\"},\n",
    "  {\"Hand thickening observed\": \"absent\"},\n",
    "  {\"Finger ulcers observed\": \"absent\"},\n",
    "  {\"Weakness on exam\": \"absent\"},\n",
    "  {\"obesity by vital signs\": \"absent\"},\n",
    "  {\"high blood pressure when checked\": \"absent\"},\n",
    "  {\"Red eye observed\": \"absent\"},\n",
    "  {\"Neck masses or fullness observed\": \"absent\"},\n",
    "  {\"Halitosis observed\": \"absent\"},\n",
    "  {\"Joint swelling observed\": \"absent\"},\n",
    "  {\"Enlargement of knuckles, finger deformities, or deviation of fingers\": \"absent\"},\n",
    "  {\"Rheumatoid nodules\": \"absent\"}\n",
    "]\n",
    "\n",
    "# Haven't really gotten this far to know what all resting results we'd have - made up 5 so that it doesn't error\n",
    "testing_details = [ \n",
    "    {\"Hyperlipidemia on lab testing\": \"present\"}, \n",
    "    {\"ANA strong positive\": \"absent\"},\n",
    "    {\"MBS shows aspiration\": \"absent\"},\n",
    "    {\"CT shows ILD\": \"absent\"}, \n",
    "    {\"CXR shows widened mediastinum\": \"absent\"}\n",
    "]\n",
    "\n",
    "details_dict: Dict[CategoryKey, List[dict]] = {\n",
    "    \"hpi\": hpi_details,\n",
    "    \"hist\": hist_details,\n",
    "    \"soc\": soc_details,\n",
    "    \"obj\": obj_details,\n",
    "    \"test\": testing_details,\n",
    "    \"subjective-and-historical\": hpi_details + hist_details + soc_details\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clinical_context_string(cat_key): \n",
    "    \"\"\"Takes the category of info and returns a sentence summarizing which clinical features are present,\n",
    "    with each feature on its own line preceded by a count-number.\"\"\"\n",
    "    lines = [f\"Here are the particular findings of the {cat_key} in this case:\"]\n",
    "    count = 1\n",
    "    for detail in details_dict[cat_key]:\n",
    "        # Each detail is a dictionary with one key-value pair\n",
    "        for feature, status in detail.items():\n",
    "            lines.append(f\"{count}. {feature} is {status}.\")\n",
    "            count += 1\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(generate_clinical_context_string(\"subjective-and-historical\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Derived Overall Likelihood ratios\n",
    "\n",
    "for positive feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Output Subdirectories\n",
    "overall_gen_output_dir = os.path.join(output_directory, \"overall_gen\")\n",
    "if not os.path.exists(overall_gen_output_dir):\n",
    "    os.makedirs(overall_gen_output_dir)\n",
    "    print(f\"Directory '{overall_gen_output_dir}' created.\")\n",
    "\n",
    "overall_spec_output_dir = os.path.join(output_directory, \"overall_spec\")\n",
    "if not os.path.exists(overall_spec_output_dir):\n",
    "    os.makedirs(overall_spec_output_dir)\n",
    "    print(f\"Directory '{overall_spec_output_dir}' created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Overall LR Estimator\n",
    "\n",
    "This answers the question: in general, what are the most helpful pieces of evidence in support of a diagnosis? \n",
    "\n",
    "\n",
    "Inputs: Each entry from the learner’s differential\n",
    "\n",
    "Outputs: A list of key evidence that would support each entry in the diagnosis. \n",
    "\n",
    "Challenges:\n",
    "- Learners may list many possible diagnoses, requiring feedback across a broad range.\n",
    "\n",
    "\n",
    "Approach:\n",
    "- for each entry on the provided diagnoses, ask the LLM to come up with the 5 strongest pieces of evidence in support of that diagnosis in each of the following categories.. \n",
    "\t- HPI, Context (Medical, Surgical, Medications, Social, Family), Vitals/Exam, and Testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate structured prompt for general, overall likelihoods\n",
    "def generate_overall_gen_prompt(diagnosis, cat_key):\n",
    "  category_of_info = categories_of_info_dict[cat_key]\n",
    "  return f\"\"\"You are given:\n",
    "- {diagnosis}: the diagnosis in question.\n",
    "- {cat_key}: the single category of information to consider. \n",
    "  Valid categories: [hpi, hist, soc, obj, test, all-but-obj].\n",
    "\n",
    "Definition of {cat_key}:\n",
    "{category_of_info}\n",
    "\n",
    "#### Task\n",
    "1. List the top 5 pieces of information from {cat_key} that most strongly support having {diagnosis}.\n",
    "2. List the top 5 pieces of information from {cat_key} that most strongly support not having {diagnosis}.\n",
    "\n",
    "#### Constraints\n",
    "- Base your reasoning on the likelihood ratio (the likelihood of the finding in patients with {diagnosis} divided by the likelihood of the finding in patients without {diagnosis}): \n",
    "  - Pieces of evidence with higher likelihood ratios (occur with greater frequency in patients with {diagnosis} than in patients without {diagnosis}) are stronger evidence in favor of {diagnosis} than pieces of evidence with lower likelihood ratios.\n",
    "  - Pieces of evidence with -in particular- a higher specificity have higher likelihood ratios. A higher sensitivity also helps, but less so than specificity. \n",
    "  - Pieces of evidence with lower likelihood ratios (meaning, they much more often occur in patients without {diagnosis} than with {diagnosis}) are stronger evidence against {diagnosis} being present. \n",
    "  - In particular, a negative result for a test with a higher sensitivity will translate to a lower likelihood ratio, and stronger evidence against {diagnosis}\n",
    "- Reason using all available sources of information (epidemiology, physiology, trials, etc.) to give your best guess. \n",
    "- Provide no numeric LRs, only a relative ranking.\n",
    "- Return only JSON in the following structure:\n",
    "    {{\n",
    "      \"for_diagnosis_strongest_evidence\": [\n",
    "        {{\n",
    "          \"finding\": \"A finding relevant to {diagnosis} from {category_of_info}\",\n",
    "          \"explanation\": \"Why this finding favors {diagnosis}\",\n",
    "          \"abbreviation_expansion\": {{\n",
    "            \"abbreviation\": \"Expanded term if an abbreviation is used\"\n",
    "          }}\n",
    "        }},\n",
    "        \"... (4 more items) ...\"\n",
    "      ],\n",
    "      \"against_diagnosis_strongest_evidence\": [\n",
    "        {{\n",
    "          \"finding\": \"A finding relevant to not having {diagnosis} from {category_of_info}\",\n",
    "          \"explanation\": \"Why this finding favors that {diagnosis} is not present\",\n",
    "          \"abbreviation_expansion\": {{}}\n",
    "        }},\n",
    "        \"... (4 more items) ...\"\n",
    "      ],\n",
    "      \"summary\": \"A short paragraph describing the overall rationale and key differences.\"\n",
    "    }}\n",
    "- Exactly 5 items under each list, no more, no fewer.\n",
    "- Define abbreviations in 'abbreviation_expansion' if used; otherwise leave it empty.\n",
    "- Do not add text outside the JSON. \n",
    "- Output must be syntactically valid JSON, with no trailing commas.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume these functions and variables are defined elsewhere:\n",
    "# generate_overall_gen_prompt(diagnosis, cat_key)\n",
    "# call_openai_api(prompt, model_run)\n",
    "# overall_gen_output_dir is a directory where you want to save output\n",
    "# model_run is defined (e.g., \"4o-mini\", \"4o\", or \"o3-mini\")\n",
    "# diagnosis is the diagnosis you're generating evidence for\n",
    "# categories_of_info_dict is a dictionary like:\n",
    "# {\n",
    "#    \"hpi\": \"History of Present Illness (the description from the onset of symptoms up to and including the patient's present experience)\",\n",
    "#    \"hist\": \"Medical and Surgical History, including Medications\",\n",
    "#    \"soc\": \"Social History, Health Behaviors, and Family History\",\n",
    "#    \"obj\": \"Vitals and Physical Exam\",\n",
    "#    \"test\": \"Test Results (labs, imaging, procedures, etc.)\"\n",
    "# }\n",
    "\n",
    "if only_overall:\n",
    "    details_dict = {\"subjective-and-historical\": details_dict[\"subjective-and-historical\"]}\n",
    "    categories_of_info_dict = {\n",
    "        \"subjective-and-historical\": categories_of_info_dict[\"subjective-and-historical\"]\n",
    "    }\n",
    "    # drops the other categories so that only is ordered list is requested from the LLMs\n",
    "\n",
    "for diagnosis in differential_diagnoses:\n",
    "    # Define output file name\n",
    "    excel_filename = os.path.join(overall_gen_output_dir, f\"{diagnosis}_gen_overall.xlsx\")\n",
    "    writer = pd.ExcelWriter(excel_filename, engine=\"openpyxl\")\n",
    "\n",
    "    # Iterate over each category in the dictionary\n",
    "    for cat_key, category_description in categories_of_info_dict.items():\n",
    "        print(f\"Overall/Gen Processing {diagnosis} overall ({cat_key})...\")\n",
    "        \n",
    "        # Generate the prompt for the current category using the overall prompt function\n",
    "        prompt = generate_overall_gen_prompt(diagnosis, cat_key)\n",
    "        \n",
    "        try:\n",
    "            # Call the LLM API; this function should return a parsed JSON matching the expected schema.\n",
    "            parsed_response = call_openai_api(prompt, model_run)\n",
    "            \n",
    "            # Extract the two lists of evidence from the response\n",
    "            evidence_for = parsed_response[\"for_diagnosis_strongest_evidence\"]\n",
    "            evidence_against = parsed_response[\"against_diagnosis_strongest_evidence\"]\n",
    "            \n",
    "            # Create rows for a DataFrame: one row per evidence item (5 total)\n",
    "            rows = []\n",
    "            for i in range(5):\n",
    "                finding_for = evidence_for[i][\"finding\"]\n",
    "                rationale_for = evidence_for[i][\"explanation\"]\n",
    "                finding_against = evidence_against[i][\"finding\"]\n",
    "                rationale_against = evidence_against[i][\"explanation\"]\n",
    "                rows.append([finding_for, rationale_for, finding_against, rationale_against])\n",
    "            \n",
    "            # Create a DataFrame with the four desired columns\n",
    "            df = pd.DataFrame(rows, columns=[\n",
    "                f\"Supports {diagnosis}\",\n",
    "                f\"Rationale for {diagnosis}\",\n",
    "                f\"Against {diagnosis}\",\n",
    "                f\"Rationale Against {diagnosis}\"\n",
    "            ])\n",
    "            \n",
    "            # Write the DataFrame to an Excel sheet named after the category key (limited to 31 chars)\n",
    "            df.to_excel(writer, sheet_name=cat_key[:31], index=False)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {diagnosis} - {category_description}: {e}\")\n",
    "\n",
    "    # Save the Excel file after processing all categories\n",
    "    writer.close()\n",
    "    print(f\"Saved results to {excel_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case-Specific, Overall Likelihood Ratios\n",
    "\n",
    "Answers the qeustion - given the details of this case, what are the pieces of evidence that strongest support diagnosis A?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate structured prompt for case-specific, overall likelihoods\n",
    "def generate_overall_spec_prompt(diagnosis, cat_key):\n",
    "  \"\"\"\n",
    "    Takes the diagnosis under consideration, and a cat_key and generates a prompt for estimating which likelihood ratios are most important in this particular case.\n",
    "    It generates the context from the cat_key and the global detail_lists\n",
    "  \"\"\"\n",
    "  category_of_info = categories_of_info_dict[cat_key]\n",
    "  clinical_context = generate_clinical_context_string(cat_key)\n",
    "  return f\"\"\"You are given:\n",
    "- {diagnosis}: the diagnosis in question.\n",
    "- and a list of the key clinical findings from the {cat_key} ({category_of_info}) and whether they were present or not \n",
    "\n",
    "#### Task\n",
    "1. List the top 5 pieces of information from the this particular case that most strongly support having {diagnosis}.\n",
    "2. List the top 5 pieces of information from the this particular case that most strongly support not having {diagnosis}.\n",
    "\n",
    "#### Clinical Context\n",
    "Here is the clinical context: \n",
    "{clinical_context}\n",
    "\n",
    "#### Constraints\n",
    "- Only consider the findings mentioned in the clinical context. Assume all other pieces of information are unknown (and thus do not change the likelihood of disease)\n",
    "- Base your reasoning on the likelihood ratio (the likelihood of the finding in patients with {diagnosis} divided by the likelihood of the finding in patients without {diagnosis}): \n",
    "  - Pieces of evidence with higher likelihood ratios (occur with greater frequency in patients with {diagnosis} than in patients without {diagnosis}) are stronger evidence in favor of {diagnosis} than pieces of evidence with lower likelihood ratios.\n",
    "  - Pieces of evidence with -in particular- a higher specificity have higher likelihood ratios. A higher sensitivity also helps, but less so than specificity. \n",
    "  - Pieces of evidence with lower likelihood ratios (meaning, they much more often occur in patients without {diagnosis} than with {diagnosis}) are stronger evidence against {diagnosis} being present. \n",
    "  - In particular, a negative result for a test with a higher sensitivity will translate to a lower likelihood ratio, and stronger evidence against {diagnosis}\n",
    "- Reason using all available sources of information (epidemiology, physiology, trials, etc.) to give your best guess. \n",
    "- Provide no numeric LRs, only a relative ranking. Give the strongest piece of evidence (highest LR) first\n",
    "\n",
    "- Return only JSON in the following structure:\n",
    "    {{\n",
    "      \"for_diagnosis_strongest_evidence\": [\n",
    "        {{\n",
    "          \"finding\": \"A finding relevant to {diagnosis} from {category_of_info}\",\n",
    "          \"explanation\": \"Why this finding favors {diagnosis}\",\n",
    "          \"abbreviation_expansion\": {{\n",
    "            \"abbreviation\": \"Expanded term if an abbreviation is used\"\n",
    "          }}\n",
    "        }},\n",
    "        \"... (4 more items) ...\"\n",
    "      ],\n",
    "      \"against_diagnosis_strongest_evidence\": [\n",
    "        {{\n",
    "          \"finding\": \"A finding relevant to not having {diagnosis} from {category_of_info}\",\n",
    "          \"explanation\": \"Why this finding favors that {diagnosis} is not present\",\n",
    "          \"abbreviation_expansion\": {{}}\n",
    "        }},\n",
    "        \"... (4 more items) ...\"\n",
    "      ],\n",
    "      \"summary\": \"A short paragraph describing the overall rationale and key differences.\"\n",
    "    }}\n",
    "\n",
    "- Exactly 5 items under each list, no more, no fewer.\n",
    "- If a finding is not mentioned in the clinical context, it should not be given as an answer. \n",
    "- Define abbreviations in 'abbreviation_expansion' if used; otherwise leave it empty.\n",
    "- Do not add text outside the JSON. \n",
    "- Output must be syntactically valid JSON, with no trailing commas.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if only_overall:\n",
    "    details_dict = {\"subjective-and-historical\": details_dict[\"subjective-and-historical\"]}\n",
    "    categories_of_info_dict = {\n",
    "        \"subjective-and-historical\": categories_of_info_dict[\"subjective-and-historical\"]\n",
    "    }\n",
    "    # drops the other categories so that only is ordered list is requested from the LLMs\n",
    "    \n",
    "for diagnosis in differential_diagnoses:\n",
    "    # Define output file name\n",
    "    excel_filename = os.path.join(overall_spec_output_dir, f\"{diagnosis}_spec_overall.xlsx\")\n",
    "    writer = pd.ExcelWriter(excel_filename, engine=\"openpyxl\")\n",
    "\n",
    "    # Iterate over each category in the dictionary\n",
    "    for cat_key, category_description in categories_of_info_dict.items():\n",
    "        print(f\"Overall/Spec Processing {diagnosis} overall ({cat_key})...\")\n",
    "        \n",
    "        # Generate the prompt for the current category using the overall prompt function\n",
    "        prompt = generate_overall_spec_prompt(diagnosis, cat_key)\n",
    "        \n",
    "        try:\n",
    "            # Call the LLM API; this function should return a parsed JSON matching the expected schema.\n",
    "            parsed_response = call_openai_api(prompt, model_run)\n",
    "            \n",
    "            # Extract the two lists of evidence from the response\n",
    "            evidence_for = parsed_response[\"for_diagnosis_strongest_evidence\"]\n",
    "            evidence_against = parsed_response[\"against_diagnosis_strongest_evidence\"]\n",
    "            \n",
    "            # Create rows for a DataFrame: one row per evidence item (5 total)\n",
    "            rows = []\n",
    "            for i in range(5):\n",
    "                finding_for = evidence_for[i][\"finding\"]\n",
    "                rationale_for = evidence_for[i][\"explanation\"]\n",
    "                finding_against = evidence_against[i][\"finding\"]\n",
    "                rationale_against = evidence_against[i][\"explanation\"]\n",
    "                rows.append([finding_for, rationale_for, finding_against, rationale_against])\n",
    "            \n",
    "            # Create a DataFrame with the four desired columns\n",
    "            df = pd.DataFrame(rows, columns=[\n",
    "                f\"Supports {diagnosis}\",\n",
    "                f\"Rationale for {diagnosis}\",\n",
    "                f\"Against {diagnosis}\",\n",
    "                f\"Rationale Against {diagnosis}\"\n",
    "            ])\n",
    "            \n",
    "            # Write the DataFrame to an Excel sheet named after the category key (limited to 31 chars)\n",
    "            df.to_excel(writer, sheet_name=cat_key[:31], index=False)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {diagnosis} - {category_description}: {e}\")\n",
    "\n",
    "    # Save the Excel file after processing all categories\n",
    "    writer.close()\n",
    "    print(f\"Saved results to {excel_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential Likelihood Ratios\n",
    "\n",
    "for corrective feedback on information gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Output Subdirectories\n",
    "diff_gen_output_dir = os.path.join(output_directory, \"diff_gen\")\n",
    "if not os.path.exists(diff_gen_output_dir):\n",
    "    os.makedirs(diff_gen_output_dir)\n",
    "    print(f\"Directory '{diff_gen_output_dir}' created.\")\n",
    "\n",
    "diff_spec_output_dir = os.path.join(output_directory, \"diff_spec\")\n",
    "if not os.path.exists(diff_spec_output_dir):\n",
    "    os.makedirs(diff_spec_output_dir)\n",
    "    print(f\"Directory '{diff_spec_output_dir}' created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General, differential likelihood ratio estimators\n",
    "\n",
    "This answers the question: in general, what are the features that differentiate between Disease A and Disease B. (not specific to a particular case)\n",
    "\n",
    "Inputs: Correct diagnosis, learner’s differential, and transcript.\n",
    "\n",
    "Outputs: A list of key evidence that differentiates cases where the learner’s differential diagnosis was correct vs. the actual correct diagnosis.\n",
    "\n",
    "Challenges:\n",
    "- Learners may list many possible diagnoses, requiring feedback across a broad range.\n",
    "- Usefulness is measured by differential LR (A vs. B) rather than the usual (overall) LR (A vs. not A).\n",
    "\n",
    "Approach:\n",
    "- Collected all DDx from Cory's list; in production, this can be auto-extracted from the transcript.\n",
    "- Used GPT-4o to identify key discriminating factors in:\n",
    "\t- HPI, Context (Medical, Surgical, Medications, Social, Family), Vitals/Exam, and Testing.\n",
    "- In production, we’d automate detecting whether the learner asked about these factors and generate feedback:\n",
    "\t- “X was important, and you asked it.”\n",
    "\t- “Y was important, but you didn’t ask it.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate structured prompt for general differential likelihoods\n",
    "def generate_diff_gen_prompt(correct_diagnosis, differential_diagnosis, cat_key):\n",
    "  category_of_info = categories_of_info_dict[cat_key]\n",
    "  return f\"\"\"\n",
    "You are asked to identify the clinical findings that most strongly discriminate between cases of the following two diagnoses:\n",
    "{correct_diagnosis} and {differential_diagnosis}.\n",
    "\n",
    "{cat_key}: the single category of information to consider. \n",
    "Valid categories: [hpi, hist, soc, obj, test].\n",
    "\n",
    "Definition of {cat_key}:\n",
    "{category_of_info}\n",
    "\n",
    "Your responses must be:\n",
    "- Accurate and valid for research-level work.\n",
    "- Relevant to each diagnosis's typical presentation, focusing on the **differential** likelihood ratio\n",
    "  (i.e., how well a finding discriminates {correct_diagnosis} from {differential_diagnosis}).\n",
    "  - Pieces of evidence with higher differential likelihood ratio (occur with greater frequency in patients with {correct_diagnosis} than in patients with {differential_diagnosis}) are stronger evidence in favor of {correct_diagnosis} than pieces of evidence with lower differential likelihood ratios.\n",
    "  - Pieces of evidence with lower likelihood ratios (meaning, they much more often occur in patients without {differential_diagnosis} than with {correct_diagnosis}) are stronger evidence against {correct_diagnosis} being present. \n",
    "- Strictly formatted in JSON to facilitate downstream parsing.\n",
    "- Explicit about any abbreviations (with definitions), if used.\n",
    "\n",
    "### Context and Focus:\n",
    "- Only consider clinical information from {category_of_info}.\n",
    "- Emphasize which pieces of information best distinguish {correct_diagnosis} from {differential_diagnosis}.\n",
    "- You do not need numeric likelihood ratios. Just rank the findings in order of their discriminative power.\n",
    "\n",
    "### Task:\n",
    "1. List the top 5 pieces of information (within {cat_key}) that most strongly support {correct_diagnosis} over {differential_diagnosis}.\n",
    "2. List the top 5 pieces of information (within {cat_key}) that most strongly support {differential_diagnosis} over {correct_diagnosis}.\n",
    "\n",
    "### Output Format (Strict JSON):\n",
    "{{\n",
    "  \"diagnosisA_strongest_evidence\": [\n",
    "    {{\n",
    "      \"finding\": \"Relevant finding favoring {correct_diagnosis}\",\n",
    "      \"explanation\": \"Short reason this finding favors {correct_diagnosis}\",\n",
    "      \"abbreviation_expansion\": {{\n",
    "        \"abbreviation\": \"Expanded term if abbreviation is used\"\n",
    "      }}\n",
    "    }},\n",
    "    \"... (total of 5 items) ...\"\n",
    "  ],\n",
    "  \"diagnosisB_strongest_evidence\": [\n",
    "    {{\n",
    "      \"finding\": \"Relevant finding favoring {differential_diagnosis}\",\n",
    "      \"explanation\": \"Short reason this finding favors {differential_diagnosis}\",\n",
    "      \"abbreviation_expansion\": {{}}\n",
    "    }},\n",
    "    \"... (total of 5 items) ...\"\n",
    "  ],\n",
    "  \"summary\": \"Short paragraph describing overall rationale.\"\n",
    "}}\n",
    "\n",
    "### Additional Constraints:\n",
    "- Each list (diagnosisA_strongest_evidence, diagnosisB_strongest_evidence) must contain exactly 5 items.\n",
    "- If abbreviations are used (e.g., ACS, GERD), define them in 'abbreviation_expansion'. Otherwise, use an empty object.\n",
    "- Provide no extra commentary outside of the JSON.\n",
    "- Return **only** the JSON in your final answer.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if only_overall:\n",
    "    details_dict = {\"subjective-and-historical\": details_dict[\"subjective-and-historical\"]}\n",
    "    categories_of_info_dict = {\n",
    "        \"subjective-and-historical\": categories_of_info_dict[\"subjective-and-historical\"]\n",
    "    }\n",
    "    # drops the other categories so that only is ordered list is requested from the LLMs\n",
    "    \n",
    "# Iterate through differential diagnoses\n",
    "for differential_diagnosis in differential_diagnoses:    \n",
    "    if differential_diagnosis != correct_diagnosis: \n",
    "        # Iterate through each category of information\n",
    "        excel_filename = os.path.join(diff_gen_output_dir, f\"{correct_diagnosis}_vs_{differential_diagnosis}.xlsx\")\n",
    "        writer = pd.ExcelWriter(excel_filename, engine=\"openpyxl\")\n",
    "        for cat_key, category_description in categories_of_info_dict.items():\n",
    "            print(f\"Diff/Gen Processing {correct_diagnosis} vs {differential_diagnosis} ({cat_key})...\")\n",
    "            \n",
    "            # Generate prompt for this category\n",
    "            prompt = generate_diff_gen_prompt(correct_diagnosis, differential_diagnosis, cat_key)\n",
    "\n",
    "            # Call the API\n",
    "            try:\n",
    "                parsed_response = call_openai_api(prompt, model_run)\n",
    "\n",
    "                # Extract relevant data\n",
    "                diagnosisA_data = parsed_response[\"diagnosisA_strongest_evidence\"]\n",
    "                diagnosisB_data = parsed_response[\"diagnosisB_strongest_evidence\"]\n",
    "\n",
    "                # Create DataFrame\n",
    "                rows = []\n",
    "                for i in range(5):\n",
    "                    findingA = diagnosisA_data[i][\"finding\"]\n",
    "                    rationaleA = diagnosisA_data[i][\"explanation\"]\n",
    "                    findingB = diagnosisB_data[i][\"finding\"]\n",
    "                    rationaleB = diagnosisB_data[i][\"explanation\"]\n",
    "                    rows.append([findingA, rationaleA, findingB, rationaleB])\n",
    "\n",
    "                df = pd.DataFrame(rows, columns=[\n",
    "                    f\"Supports {correct_diagnosis}\",\n",
    "                    f\"Rationale {correct_diagnosis}\",\n",
    "                    f\"Supports {differential_diagnosis}\",\n",
    "                    f\"Rationale {differential_diagnosis}\"\n",
    "                ])\n",
    "\n",
    "                # Write to corresponding sheet\n",
    "                df.to_excel(writer, sheet_name=cat_key[:31], index=False)  # Excel sheet names are limited to 31 chars\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {differential_diagnosis} - {cat_key}: {e}\")\n",
    "\n",
    "        # Save Excel file after all category sheets are added\n",
    "        writer.close()\n",
    "        print(f\"Saved results to {excel_filename}\")\n",
    "print(\"All processing completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case-specific, differential likelihood ratio estimators\n",
    "\n",
    "This answers the question: in this particular case (with features x,y,z), what are the features that differentiate between this case of Disease A and a hypothetical case of Disease B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate structured prompt for case-specific differential likelihoods\n",
    "def generate_diff_spec_prompt(correct_diagnosis, differential_diagnosis, cat_key):\n",
    "  \"\"\"\n",
    "    - Takes the correct diagnosis, another diagnosis that a learnering might have suggested, and a cat_key \n",
    "    - generates a prompt for estimating which differential likelihood ratios are most important in this particular case.\n",
    "    - it will return a list only of findings that were present in the case\n",
    "    - It generates the context from the cat_key and the global detail_lists\n",
    "  \"\"\"\n",
    "  category_of_info = categories_of_info_dict[cat_key]\n",
    "  clinical_context = generate_clinical_context_string(cat_key)\n",
    "  return f\"\"\"\n",
    "You are asked to identify the clinical findings from a particular case that most strongly discriminate between cases of the following two diagnoses:\n",
    "{correct_diagnosis} and {differential_diagnosis}.\n",
    "\n",
    "You are given:\n",
    "- the two diagnoses under consideration: {correct_diagnosis} and {differential_diagnosis}\n",
    "- and a list of the key clinical findings from the {cat_key} ({category_of_info}) and whether they were present or not \n",
    "- only findings given in the clinical context are under consideration\n",
    "\n",
    "#### Task\n",
    "Your task is to identify the pieces of evidence from the clinical context that argue most strongly for one of the two diagnoses: \n",
    "1. List the top 5 pieces of information (from the clinical context) that most strongly support {correct_diagnosis} over {differential_diagnosis}.\n",
    "2. List the top 5 pieces of information (from the clinical context) that most strongly support {differential_diagnosis} over {correct_diagnosis}.\n",
    "\n",
    "#### Clinical Context\n",
    "Here is the clinical context: \n",
    "{clinical_context}\n",
    "\n",
    "#### Constraints\n",
    "- Only consider the findings mentioned in the clinical context. Assume all other pieces of information are unknown (and thus do not change the likelihood of disease)\n",
    "- Base your reasoning on each diagnosis' usual presentation, focusing on the **differential** likelihood ratio\n",
    "  (i.e., how well a finding discriminates {correct_diagnosis} from {differential_diagnosis}).\n",
    "  - Pieces of evidence with higher differential likelihood ratio (occur with greater frequency in patients with {correct_diagnosis} than in patients with {differential_diagnosis}) are stronger evidence in favor of {correct_diagnosis} than pieces of evidence with lower differential likelihood ratios.\n",
    "  - Pieces of evidence with lower likelihood ratios (meaning, they much more often occur in patients without {differential_diagnosis} than with {correct_diagnosis}) are stronger evidence against {correct_diagnosis} being present. \n",
    "- Reason using all available sources of information (epidemiology, physiology, trials, etc.) to give your best guess. \n",
    "- Provide no numeric LRs, only a relative ranking. Give the strongest piece of evidence (highest LR) first\n",
    "- Emphasize which pieces of information best distinguish {correct_diagnosis} from {differential_diagnosis}.\n",
    "\n",
    "### Output Format (Strict JSON):\n",
    "{{\n",
    "  \"diagnosisA_strongest_evidence\": [\n",
    "    {{\n",
    "      \"finding\": \"Relevant finding favoring {correct_diagnosis}\",\n",
    "      \"explanation\": \"Short reason this finding favors {correct_diagnosis}\",\n",
    "      \"abbreviation_expansion\": {{\n",
    "        \"abbreviation\": \"Expanded term if abbreviation is used\"\n",
    "      }}\n",
    "    }},\n",
    "    \"... (total of 5 items) ...\"\n",
    "  ],\n",
    "  \"diagnosisB_strongest_evidence\": [\n",
    "    {{\n",
    "      \"finding\": \"Relevant finding favoring {differential_diagnosis}\",\n",
    "      \"explanation\": \"Short reason this finding favors {differential_diagnosis}\",\n",
    "      \"abbreviation_expansion\": {{}}\n",
    "    }},\n",
    "    \"... (total of 5 items) ...\"\n",
    "  ],\n",
    "  \"summary\": \"Short paragraph describing overall rationale.\"\n",
    "}}\n",
    "\n",
    "- Exactly 5 items under each list, no more, no fewer.\n",
    "- If a finding is not mentioned in the clinical context, it should not be given as an answer. \n",
    "- Define abbreviations in 'abbreviation_expansion' if used; otherwise leave it empty.\n",
    "- Do not add text outside the JSON. \n",
    "- Output must be syntactically valid JSON, with no trailing commas.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if only_overall:\n",
    "    details_dict = {\"subjective-and-historical\": details_dict[\"subjective-and-historical\"]}\n",
    "    categories_of_info_dict = {\n",
    "        \"subjective-and-historical\": categories_of_info_dict[\"subjective-and-historical\"]\n",
    "    }\n",
    "    # drops the other categories so that only is ordered list is requested from the LLMs\n",
    "\n",
    "# Iterate through differential diagnoses\n",
    "for differential_diagnosis in differential_diagnoses:\n",
    "    if differential_diagnosis != correct_diagnosis: \n",
    "        # Iterate through each category of information\n",
    "        excel_filename = os.path.join(diff_spec_output_dir, f\"{correct_diagnosis}_vs_{differential_diagnosis}.xlsx\")\n",
    "        writer = pd.ExcelWriter(excel_filename, engine=\"openpyxl\")\n",
    "        for cat_key, category_description in categories_of_info_dict.items():\n",
    "            print(f\"Diff/Spec: Processing {correct_diagnosis} vs {differential_diagnosis} ({cat_key})...\")\n",
    "            \n",
    "            # Generate prompt for this category\n",
    "            prompt = generate_diff_spec_prompt(correct_diagnosis, differential_diagnosis, cat_key)\n",
    "\n",
    "            # Call the API\n",
    "            try:\n",
    "                parsed_response = call_openai_api(prompt, model_run)\n",
    "\n",
    "                # Extract relevant data\n",
    "                diagnosisA_data = parsed_response[\"diagnosisA_strongest_evidence\"]\n",
    "                diagnosisB_data = parsed_response[\"diagnosisB_strongest_evidence\"]\n",
    "\n",
    "                # Create DataFrame\n",
    "                rows = []\n",
    "                for i in range(5):\n",
    "                    findingA = diagnosisA_data[i][\"finding\"]\n",
    "                    rationaleA = diagnosisA_data[i][\"explanation\"]\n",
    "                    findingB = diagnosisB_data[i][\"finding\"]\n",
    "                    rationaleB = diagnosisB_data[i][\"explanation\"]\n",
    "                    rows.append([findingA, rationaleA, findingB, rationaleB])\n",
    "\n",
    "                df = pd.DataFrame(rows, columns=[\n",
    "                    f\"Supports {correct_diagnosis}\",\n",
    "                    f\"Rationale {correct_diagnosis}\",\n",
    "                    f\"Supports {differential_diagnosis}\",\n",
    "                    f\"Rationale {differential_diagnosis}\"\n",
    "                ])\n",
    "\n",
    "                # Write to corresponding sheet\n",
    "                df.to_excel(writer, sheet_name=cat_key[:31], index=False)  # Excel sheet names are limited to 31 chars\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {differential_diagnosis} - {cat_key}: {e}\")\n",
    "\n",
    "        # Save Excel file after all category sheets are added\n",
    "        writer.close()\n",
    "        print(f\"Saved results to {excel_filename}\")\n",
    "print(\"All processing completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to test how large each prompt is, to assess what we should set the max_tokens to. \n",
    "\n",
    "About 1500 is the largest\n",
    "(max_token = 1600-1800 should suffice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Choose an encoding for your model (e.g., for GPT-4 or ChatGPT models)\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "#prompt = generate_diff_spec_prompt(\"CREST syndrome with Type 2 Achalasia\", \"Esophageal stricture\", \"hpi\")\n",
    "#prompt = generate_diff_gen_prompt(\"CREST syndrome with Type 2 Achalasia\", \"Esophageal stricture\", \"hpi\")\n",
    "#prompt = generate_overall_gen_prompt(\"CREST syndrome with Type 2 Achalasia\", \"hpi\")\n",
    "prompt = generate_overall_spec_prompt(\"CREST syndrome with Type 2 Achalasia\", \"hpi\")\n",
    "token_count = len(encoding.encode(prompt))\n",
    "print(\"Token count:\", token_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reasoning Feedback\n",
    "\n",
    "Clinical Reasoning Feedback\n",
    "\n",
    "Though we know, for certain, the correct diagnosis (because we made up the case) - in reality, clinicians never know anything with absolute certainty. However, what we can know is: \n",
    "\n",
    "1. A rank-ordering of what diagnoses are most likely, given the information at hand\n",
    "2. Estimates of how likely each data point is, assuming a given pre-test probability\n",
    "\n",
    "In order to provide normative (ie. how *should* the learner reason) feedback on these, we must create a statistical model that will (hopefully) correspond closely to reality. \n",
    "\n",
    "- Inputs: Differential diagnosis + encounter transcript.\n",
    "- Output: Likelihood estimates for each diagnosis based on discussed information.\n",
    "- Challenges:\t\n",
    "\t- Limited “Does this patient have X?” data in many contexts\n",
    "\t- Bayesian reasoning depends on assumptions that may not hold (e.g. independence of information; similar spectrum of patients to where data derived).\n",
    "\n",
    "- Approach: \n",
    "\t- Extract key information with known likelihood ratios and estimate a few additional important features.\n",
    "\t- Apply multi-class, qualitative Bayesian reasoning to assess likelihood of each diagnosis (https://mybinder.org/v2/gh/reblocke/notebooks_dx_reasoning/HEAD?urlpath=voila/render/multi_class.ipynb) based on learner-gathered data.\n",
    "\t- In production, compare calculated estimates to actual outcomes.\n",
    "\n",
    "- Next Steps:\n",
    "\t- Not yet done, but if this approach seems valid, I can apply it to available transcripts.\n",
    "\t- Clinician input needed to assess whether qualitative Bayesian estimates align with clinical judgment (since no reference standard exists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement this from other worksheet - will need info from the interviews for this to work (though can test-run on all information)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
