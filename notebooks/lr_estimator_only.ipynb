{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Repository setup for portable, repo-relative paths\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "def _find_repo_root(start: Path | None = None) -> Path:\n",
    "    start = (start or Path.cwd()).resolve()\n",
    "    for candidate in [start, *start.parents]:\n",
    "        if (candidate / \"pyproject.toml\").exists():\n",
    "            return candidate\n",
    "    return start\n",
    "\n",
    "REPO_ROOT = _find_repo_root()\n",
    "if str(REPO_ROOT / \"src\") not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT / \"src\"))\n",
    "\n",
    "from dx_chat_entropy.paths import get_paths\n",
    "PATHS = get_paths(REPO_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6be5ae",
   "metadata": {},
   "source": [
    "# Estimator only \n",
    "\n",
    "This workbook only estimates LRs, taking in various spreadsheet configurations. \n",
    "\n",
    "Inteded to support the use cases for the automated feedback generator. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a8efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "import json\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI  # or your appropriate client wrapper\n",
    "import math\n",
    "from dotenv import load_dotenv\n",
    "from __future__ import annotations\n",
    "\n",
    "load_dotenv()  # looks for a .env file in the current dir by default\n",
    "#print(os.getenv(\"OPENAI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd61518",
   "metadata": {},
   "source": [
    "### Old version \n",
    "\n",
    "Without any revamping to attempt to increase performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a220fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the response schema expecting a floating point number.\n",
    "class LRResponse(BaseModel):\n",
    "    value: float\n",
    "\n",
    "def estimate_lr(diagnosis: str, info_val: str, client, model: str) -> float:\n",
    "    \"\"\"\n",
    "    Calls the LLM with a prompt containing the diagnosis and a finding.\n",
    "    Returns the estimated likelihood ratio as a floating point number.\n",
    "    \"\"\"\n",
    "    lr_prompt = \"\"\"You are an expert in medical diagnosis who is giving assessments of how important a piece of information is when determining whether a patient has a particularly condition. Your task is to estimate the likelihood ratio of a finding for a disease. Recall that the likelihood ratio represents how much the ratio between the odds of disease given a result for a lab value, whether a physical exam finding is present, or whether a comorbidity is present over the odds of disease when you did not know the result.\n",
    "You will receive inputs in the following format; Target condition: <Condition, e.g. Patient Has: Cardiac chest pain>. Finding: <piece of information, e.g. ‘Patient does not have: radiation to the neck, arm, or jaw’>.\n",
    "So, for example. If the odds of a Condition Z being present was 1 (meaning 50% probability) before we knew anything, but then we got a result (Finding A) it became 2 (meaning 2:1 odds or 66% probability), then the likelihood ratio would be 2. \n",
    "Given a condition and a finding, you will provide your best estimate of the likelihood ratio as a floating point number. Return your answer in valid JSON with the following schema: { 'value': <floating point number greater than 0> }.\\n\\n\n",
    "\n",
    "Remember, stronger evidence in favor of a condition has a value farther above 1. Strong evidence against a diagnosis has a value farther below 1 (closer to 0). A likelihood ratio of 10 is equally strong evidence for a condition as a likelihood ratio of 0.1 is against it. Likelihood ratios near 1 represent weak evidence for or against. \n",
    "And if the \"patient does not have: \" some feature that is almost always present, that is strong evidence against.\n",
    "(pay attention for double negatives- Patient has: no tobacco and Patient does not have: tobacco are identical)\n",
    "\n",
    "Here is how I would like you to approach the problem:\n",
    "First, consider the condition you are predicting (Condition: ___). Is the condition a medical diagnosis? If so, what kind of findings are usually present in someone who has that condition. Does the condition specify a certain type of patient? If so, how does that change things? \n",
    "Then, consider the finding. If a finding is much more common among patients who have the condition of interest than among patients who do not have the condition of interest, then the likelihood ratio should be high. This might be because the finding is a consequence of the disease, indicates that an enabling condition is present, indicates that a frequently comorbid condition is present, or is related to the pathology of the condition. In general, likelihood ratios over about 20 are pathognomonic, above 5 or so is extremely strong evidence in favor, above 2.5 or so is strong evidence, above 1.4 is so-so evidence, and 1-1.4 is pretty weak evidence. Conversely, if the finding is more common in people who do NOT have the condition, then the likelihood ratio should be below 0. Similarly, a likelihood ratio below 0.05 would exclude the condition in most situations, below 0.2 would be extremely strong evidence against, below 0.4 would be strong evidence against, below 0.71 is so-so, and between 0.71 and 1 is pretty weak evidence against (meaning, it just doesn’t change the odds of the condition much). \n",
    "\n",
    "Here are some hypothetical examples to consider: \n",
    "    Prompt = Target condition: Cardiac Chest Pain. Finding: Patient has: Pain not worse with exertion (requires they clarify exercise 1hr after meal).\n",
    "    You would reason that because cardiac chest pain is usually worse with exertion because exertion worsens cardiac demand for oxygen, and thus worsens ischemia.\n",
    "    Response = {\n",
    "        ‘value’: 0.4\n",
    "    }\n",
    "\n",
    "    Prompt =  Target condition: Cardiac Chest Pain. Finding: Patient does not have: tobacco.\n",
    "    You would reason that because being someone who smokes increases your risk of coronary artery disease, and thus being a never smoker means you’re at less risk… but many people who have heart attacks still smoke, so it’s only a weak predictor. \n",
    "    Response = {\n",
    "        ‘value’: 0.75\n",
    "    }\n",
    "\n",
    "    Prompt = Target condition: Cardaic Chest Pain. Finding = Patient has: enjoys playing chess.\n",
    "    You would reason that because enjoying chest has no relationship to having a heart attack.\n",
    "    Response = {\n",
    "        ‘value’: 1\n",
    "    }\n",
    "\n",
    "    Prompt = Target condition: Cardiac Chest Pain. Finding = Patient has: pain located behind the sternum\n",
    "    You would reason that because cardiac chest pain is often experienced behind the sternum (thus, more likely), but so are many other causes of chest pain - like GERD.\n",
    "    Response = {\n",
    "        ‘value’: 1.2\n",
    "    }\n",
    "\n",
    "    Prompt = Condition: Cardiac Chest Pain. Finding = patient has: pain worse with exertion.\n",
    "    You would reason that because the increased myocardial oxygen consumption worsens the pain if oxygen delivery to the myocardium is the cause, as it is in heart attacks.\n",
    "    Response = {\n",
    "        ‘value’: 3.4\n",
    "    }\n",
    "\n",
    "    OK: here’s the prompt.. \"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": lr_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"Condition: {diagnosis}\\nFinding: {info_val}\"}\n",
    "    ]\n",
    "\n",
    "    # Check if the model starts with \"o3-mini\" \"o3\" \"o4-mini, \"o4\", etc.\n",
    "    kwargs = {}\n",
    "    if model.startswith(\"o\"):\n",
    "        kwargs[\"reasoning_effort\"] = \"medium\"  # low, medium, high depending on need\n",
    "\n",
    "    # Call the LLM using the provided model name.\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        response_format=LRResponse,\n",
    "        **kwargs  # pass the conditional keyword argument\n",
    "    )\n",
    "\n",
    "    # Call the LLM using the provided model name.\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=model,  # use the current model from the list\n",
    "        messages=messages,\n",
    "        response_format=LRResponse,\n",
    "    )\n",
    "    \n",
    "    # Extract and return the floating point estimate.\n",
    "    lr_response = completion.choices[0].message.parsed\n",
    "    return lr_response.value\n",
    "\n",
    "\n",
    "# Initialize the OpenAI (or your chosen) client using your API key.\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# List of model names to iterate over.\n",
    "model_names = ['gpt-4o-mini-2024-07-18'] #['gpt-4o-mini-2024-07-18', 'gpt-4.1-mini-2025-04-14', 'gpt-4.1-2025-04-14', 'o4-mini-2025-04-16'] #'gpt-4o-2024-08-06', 'o3-mini-2025-01-31', gpt-4.1-2025-04-14, o4-mini-2025-04-16, 'o3-2025-04-16']\n",
    "\n",
    "# Read the processed Excel file.\n",
    "# We use header=None so that row 0 (the diagnosis row) and row 1 (the column headers row) are preserved.\n",
    "input_filename = \"data/processed/nnt_lrs/nnt_lrs_processed.xlsx\"\n",
    "#input_filename = \"new_\" \\\n",
    "#\"data/processed/nnt_lrs/nnt_lrs_processed.xlsx\" # use this one for the substitute in\n",
    "sheets = pd.read_excel(input_filename, sheet_name=None, header=None)\n",
    "\n",
    "# Process each sheet\n",
    "for sheet_name, df in sheets.items():\n",
    "    # Set diagnosis from the first row (row index 0, first cell)\n",
    "    diagnosis = df.iloc[0, 0]\n",
    "\n",
    "    # For each model in the list, call the LLM and add a new column with the estimation.\n",
    "    for model in model_names:\n",
    "        new_col_header = \"lr_\" + model\n",
    "        new_col = []  # This list will hold one value per row\n",
    "        print(f\"Diagnosis: '{diagnosis}', Model: '{model}'\")\n",
    "\n",
    "        # Iterate over each row in the sheet.\n",
    "        # Row 0 is the diagnosis row; row 1 is the existing column labels.\n",
    "        for i in range(len(df)):\n",
    "            if i == 0:\n",
    "                new_col.append(\"\")  # Leave the diagnosis row unchanged.\n",
    "            elif i == 1:\n",
    "                new_col.append(new_col_header)  # Insert the new column header in row 1.\n",
    "            else:\n",
    "                # For data rows, use the \"finding\" from the first column (index 0)\n",
    "                info_val = df.iloc[i, 0]\n",
    "                try:\n",
    "                    estimated_lr = estimate_lr(diagnosis, info_val, client, model)\n",
    "                except Exception as e:\n",
    "                    estimated_lr = \"ERROR\"  \n",
    "                    print(f\"Error estimating LR for sheet '{sheet_name}', row {i}, model {model}: {e}\")\n",
    "                new_col.append(estimated_lr)\n",
    "        \n",
    "        # Insert the new column at the end of the dataframe.\n",
    "        df.insert(df.shape[1], new_col_header, new_col)\n",
    "    \n",
    "    # Update the sheet data in our dictionary.\n",
    "    sheets[sheet_name] = df\n",
    "\n",
    "# Write out the modified sheets to a new Excel file.\n",
    "output_filename = \"data/processed/nnt_lrs/nnt_lrs_with_estimated.xlsx\"\n",
    "with pd.ExcelWriter(output_filename, engine=\"openpyxl\") as writer:\n",
    "    for sheet_name, df in sheets.items():\n",
    "        # Write without adding pandas default headers or indices.\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False, header=False)\n",
    "\n",
    "print(f\"Processed Excel file saved as '{output_filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7560410",
   "metadata": {},
   "source": [
    "## Scripts to perform the data processing for Cory's July/2025 reasoning request\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63d74c9",
   "metadata": {},
   "source": [
    "### Reasoning about categories\n",
    "\n",
    "\"can you run the LRs for each grouping (second attachment) and add LRs to a few rows to round out the addition of a pulmonary grouping (see rows 91-94)? All additions of diagnoses or key features are highlighted in yellow. First few rows of second attachment include sub-groupings but guessing this is getting too complex for this pilot stage.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00553b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Estimate likelihood‑ratios (LRs) for every (finding × disease‑category) pair in a\n",
    "single‑sheet Excel workbook whose first column lists findings and whose first row\n",
    "lists the disease categories.\n",
    "\n",
    "Input  workbook example   :  est_lrs_by_category.xlsx\n",
    "Output workbook produced  :  est_lrs_by_category_filled.xlsx\n",
    "───────────────────────────────────────────────────────────────────────────────\n",
    "Layout assumed\n",
    "─────────────\n",
    "• Sheet #0 is the *only* sheet that will be processed.\n",
    "• Row 0 (index 0): disease‑category targets.  \n",
    "  – Cell A1 may read “Diagnosis:” or be blank; all other non‑blank cells in\n",
    "    that first row are treated as separate prediction targets.\n",
    "\n",
    "• Column 0 (index 0), rows ≥ 1: findings (free‑text strings beginning with\n",
    "  “Patient Has:” / “Patient Does Not Have:”, etc.).\n",
    "  – All other cells initially *empty* → will be populated with LR estimates.\n",
    "\n",
    "The script preserves the original layout and simply fills the empty cells with\n",
    "floating‑point LR values (or “ERROR” if the LLM call fails).\n",
    "\n",
    "Multiple models?\n",
    "────────────────\n",
    "`model_names` can contain one or many model IDs.  \n",
    "If you list more than one model, each model gets its *own* sheet in the output\n",
    "workbook, all named after the model ID.  (The original sheet is left unchanged\n",
    "in that case.)\n",
    "\n",
    "Dependencies\n",
    "────────────\n",
    "openai >= 1.0,  pydantic >= 2,  pandas,  openpyxl\n",
    "\"\"\"\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 1.  CONFIGURATION  ───────────────────────────────────────────────────────────\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "INPUT_FILE  = \"archive/legacy_runs/lr_estimation_2025_07_21/est_lrs_by_category.xlsx\"\n",
    "OUTPUT_FILE = \"archive/legacy_runs/lr_estimation_2025_07_21/est_lrs_by_category_filled.xlsx\"\n",
    "\n",
    "# Provide one or many model IDs here.\n",
    "model_names = [\"o3-2025-04-16\"] # [\"gpt-4o-mini-2024-07-18\"] \n",
    "\n",
    "# Optional: tune reasoning depth for o‑series models.\n",
    "REASONING_EFFORT = \"medium\"   # \"low\" | \"medium\" | \"high\"\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 2.  RESPONSE SCHEMA  ────────────────────────────────────────────────────────\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "class LRResponse(BaseModel):\n",
    "    value: float\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 3.  LLM CALL  ───────────────────────────────────────────────────────────────\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "LR_PROMPT_TEMPLATE = \"\"\"You are an expert in medical diagnosis whose task is\n",
    "to estimate a *likelihood ratio* (LR) for a finding with respect to a category of conditions.\n",
    "\n",
    "You are an expert in medical diagnosis who is giving assessments of how important a piece of information \n",
    "is when determining whether a patient has a particularly type of condition condition. \n",
    "\n",
    "Your task is to estimate the likelihood ratio of a finding for a category of disease. \n",
    "\n",
    "Recall that the likelihood ratio represents how much the ratio between the odds of disease given a result \n",
    "for a lab value, whether a physical exam finding is present, or whether a comorbidity is present over the \n",
    "odds of disease when you did not know the result.\n",
    "\n",
    "You will receive inputs in the following format: \n",
    "Condition: <A category of interest, followed by the specific diseases that make up that category, e.g. \"cardiac\">. \n",
    "Finding: <piece of information, e.g. ‘Patient does not have: radiation to the neck, arm, or jaw’>.\n",
    "\n",
    "So, for example. If the odds of a Condition Z being present was 1 (meaning 50% probability) before we knew anything, \n",
    "but then we got a result (Finding A) it became 2 (meaning 2:1 odds or 66% probability), \n",
    "then the likelihood ratio would be 2. \n",
    "\n",
    "Given a category of diseases and a finding, you will provide your best estimate of the likelihood ratio as a floating point number. \n",
    "Return your answer in valid JSON with the following schema: { 'value': <floating point number greater than 0> }.\\n\\n\n",
    "\n",
    "Remember, stronger evidence in favor of a condition has a value farther above 1. \n",
    "Strong evidence against a diagnosis has a value farther below 1 (closer to 0). \n",
    "A likelihood ratio of 10 is equally strong evidence for a condition as a likelihood ratio of 0.1 is against it. \n",
    "Likelihood ratios near 1 represent weak evidence for or against. \n",
    "If the \"patient does not have: \" some feature that is almost always present, that is strong evidence against.\n",
    "(pay attention for double negatives- Patient has: no tobacco and Patient does not have: tobacco are identical)\n",
    "\n",
    "Here is how I would like you to approach the problem:\n",
    "First, consider the category of diseases you are predicting (Condition: ___). \n",
    "Is the condition a medical diagnosis? \n",
    "If so, what kind of findings are usually present in someone who has that condition. \n",
    "Does the condition specify a certain type of patient? \n",
    "If so, how does that change things? \n",
    "Then, consider the finding. \n",
    "If a finding is much more common among patients who have the condition of interest than among patients who do not have the condition of interest, \n",
    "then the likelihood ratio should be high. \n",
    "This might be because the finding is a consequence of the disease, \n",
    "indicates that an enabling condition is present, \n",
    "indicates that a frequently comorbid condition is present, \n",
    "or is related to the pathology of the condition. \n",
    "\n",
    "In general, likelihood ratios over about 20 are pathognomonic, \n",
    "above 5 or so is extremely strong evidence in favor, \n",
    "above 2.5 or so is strong evidence, \n",
    "above 1.4 is so-so evidence, \n",
    "and 1-1.4 is pretty weak evidence. \n",
    "\n",
    "Conversely, if the finding is more common in people who do NOT have the condition, \n",
    "then the likelihood ratio should be below 1. \n",
    "\n",
    "Similarly, a likelihood ratio below 0.05 would exclude the condition in most situations, \n",
    "below 0.2 would be extremely strong evidence against, \n",
    "below 0.4 would be strong evidence against, \n",
    "below 0.71 is so-so, \n",
    "and between 0.71 and 1 is pretty weak evidence against (meaning, it just doesn’t change the odds of the condition much). \n",
    "\n",
    "Return JSON: {{ \"value\": <float >0 }}  (no additional keys).\n",
    "Reply *only* with the JSON object.\n",
    "\"\"\"\n",
    "\n",
    "def estimate_lr(\n",
    "    condition: str,\n",
    "    finding: str,\n",
    "    client: OpenAI,\n",
    "    model: str,\n",
    ") -> float | str:\n",
    "    \"\"\"Call the LLM and return a floating‑point LR (or the string 'ERROR').\"\"\"\n",
    "    sys_msgs = [{\"role\": \"system\", \"content\": LR_PROMPT_TEMPLATE}]\n",
    "    user_msg = {\"role\": \"user\",\n",
    "                \"content\": f\"Condition: {condition}\\nFinding: {finding}\"}\n",
    "\n",
    "    # Build request kwargs.\n",
    "    kwargs: dict = {}\n",
    "    if model.startswith(\"o\"):          # o3, o3‑mini, o4‑mini, o4, etc.\n",
    "        kwargs[\"reasoning_effort\"] = REASONING_EFFORT\n",
    "\n",
    "    print(f\"LLM call → model='{model}' | condition='{condition}' | finding='{finding}'\")\n",
    "\n",
    "    try:\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model=model,\n",
    "            messages=[*sys_msgs, user_msg],\n",
    "            response_format=LRResponse,\n",
    "            **kwargs,\n",
    "        )\n",
    "        return completion.choices[0].message.parsed.value\n",
    "    except Exception as exc:           # catch any parsing / API error\n",
    "        print(f\"LLM error ({model}): {exc}\")\n",
    "        return \"ERROR\"\n",
    "\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 4.  MAIN MATRIX‑FILLING LOGIC  ──────────────────────────────────────────────\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def fill_matrix(df: pd.DataFrame, model: str, client: OpenAI) -> pd.DataFrame:\n",
    "    \"\"\"Return a *copy* of `df` with all blank data cells filled for one model.\"\"\"\n",
    "    df_filled = df.copy(deep=True)\n",
    "\n",
    "    # Identify disease categories (non‑NaN entries) in the first row, skipping col 0.\n",
    "    categories: dict[int, str] = {col: str(df.iloc[0, col]).strip()\n",
    "                                  for col in range(1, df.shape[1])\n",
    "                                  if pd.notna(df.iloc[0, col]) and str(df.iloc[0, col]).strip()}\n",
    "    if not categories:\n",
    "        raise ValueError(\"No disease categories detected in row 0.\")\n",
    "\n",
    "    # Iterate over findings (rows ≥ 1)\n",
    "    for row in range(1, df.shape[0]):\n",
    "        finding = df.iloc[row, 0]\n",
    "        if pd.isna(finding) or not str(finding).strip():\n",
    "            # Skip completely empty rows\n",
    "            continue\n",
    "\n",
    "        for col, diagnosis in categories.items():\n",
    "            # Only fill previously blank / NaN cells.\n",
    "            if pd.isna(df_filled.iloc[row, col]) or df_filled.iloc[row, col] == \"\":\n",
    "                lr = estimate_lr(diagnosis, finding, client, model)\n",
    "                df_filled.iat[row, col] = lr\n",
    "\n",
    "    return df_filled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbca3065",
   "metadata": {},
   "source": [
    "#### Non plus_minus version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee4f2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "# 5.  DRIVER CODE  ────────────────────────────────────────────────────────────\n",
    "# ──────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def main() -> None:\n",
    "    # Load workbook (first sheet only, no header inference).\n",
    "    df = pd.read_excel(INPUT_FILE, sheet_name=0, header=None)\n",
    "\n",
    "    # drop columns that are completely empty (all NaN or all empty/whitespace)\n",
    "    df = df.loc[:, ~(df.replace(\"\", pd.NA).isna().all())]\n",
    "\n",
    "    # Initialise client.\n",
    "    client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "    # Either a single model (update in‑place) or multiple models (one sheet each).\n",
    "    with pd.ExcelWriter(OUTPUT_FILE, engine=\"openpyxl\") as writer:\n",
    "        if len(model_names) == 1:\n",
    "            filled = fill_matrix(df, model_names[0], client)\n",
    "            filled.to_excel(writer, sheet_name=\"LRs\", index=False, header=False)\n",
    "        else:\n",
    "            for model in model_names:\n",
    "                filled = fill_matrix(df, model, client)\n",
    "                filled.to_excel(writer, sheet_name=model, index=False, header=False)\n",
    "\n",
    "    print(f\"Completed workbook saved →  {OUTPUT_FILE}\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10058a0",
   "metadata": {},
   "source": [
    "#### Plus-Minus Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715fede4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plus-Minus Categories Code here\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# PLUS‑MINUS  C A T E G O R I E S\n",
    "# ---------------------------------------------------------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "INPUT_PM_CAT  = \"archive/legacy_runs/lr_estimation_2025_07_21/est_lrs_by_category_for_plusminus.xlsx\"\n",
    "OUTPUT_PM_CAT = \"archive/legacy_runs/lr_estimation_2025_07_21/est_lrs_by_category_plusminus_filled.xlsx\"\n",
    "\n",
    "# Uses the same `model_names`, `estimate_lr`, and `fill_matrix`\n",
    "# that were defined in the earlier “Reasoning about categories” section.\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "def build_plusminus_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return a new dataframe where every finding is duplicated into\n",
    "       'Patient has:' and 'Patient does not have:' variants.\"\"\"\n",
    "    header = df.iloc[0].copy()\n",
    "    findings = df.iloc[1:, 0].dropna().astype(str).str.strip()\n",
    "\n",
    "    pm_rows = []\n",
    "    for f in findings:\n",
    "        low = f.lower()\n",
    "        if low.startswith(\"patient has:\") or low.startswith(\"patient does not have:\"):\n",
    "            pm_rows.append(f)                 # already prefixed → keep single row\n",
    "        else:\n",
    "            pm_rows.append(f\"Patient has: {f}\")\n",
    "            pm_rows.append(f\"Patient does not have: {f}\")\n",
    "\n",
    "    # Build an empty frame, copy header, insert the new finding rows\n",
    "    df_pm = pd.DataFrame(\n",
    "        \"\",\n",
    "        index=range(len(pm_rows) + 1),\n",
    "        columns=df.columns,\n",
    "    )\n",
    "    df_pm.iloc[0] = header\n",
    "    df_pm.iloc[1:, 0] = pm_rows\n",
    "\n",
    "    # Drop columns that are completely empty (Excel artefacts)\n",
    "    return df_pm.loc[:, ~(df_pm.replace(\"\", pd.NA).isna().all())]\n",
    "\n",
    "\n",
    "# ––– LOAD, EXPAND, RUN –––––––––––––––––––––––––––––––––––––––––––––––––––––––\n",
    "df_orig = pd.read_excel(INPUT_PM_CAT, sheet_name=0, header=None)\n",
    "df_plusminus = build_plusminus_df(df_orig)\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "with pd.ExcelWriter(OUTPUT_PM_CAT, engine=\"openpyxl\") as writer:\n",
    "    if len(model_names) == 1:\n",
    "        fill_matrix(df_plusminus, model_names[0], client) \\\n",
    "            .to_excel(writer, sheet_name=\"LRs\", index=False, header=False)\n",
    "    else:\n",
    "        for m in model_names:\n",
    "            fill_matrix(df_plusminus, m, client) \\\n",
    "                .to_excel(writer, sheet_name=m, index=False, header=False)\n",
    "\n",
    "print(f\"✔  Plus‑minus (categories) workbook saved → {OUTPUT_PM_CAT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8231217",
   "metadata": {},
   "source": [
    "### Diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3543c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fill a (finding × disease) matrix with LLM‑estimated likelihood ratios (LRs).\n",
    "\n",
    "• Workbook layout ----------------------------------------\n",
    "  ┌───────────┬──────────────┬─────────────┬───┐\n",
    "  │           │  Col‑1       │  Col‑2      │ … │\n",
    "  │ Row‑0     │ Disease #1   │ Disease #2  │ … │ ← targets\n",
    "  │ Row‑1…N   │ Finding 1    │             │   │\n",
    "  │           │ Finding 2    │             │   │\n",
    "  └───────────┴──────────────┴─────────────┴───┘\n",
    "  – Sheet 0 only.  \n",
    "  – Column‑0 (rows ≥1) holds findings; other cells start blank and will be filled.\n",
    "\n",
    "• Multiple models?  \n",
    "  – `model_names` may list one or many model IDs.  \n",
    "  – With >1 model each sheet in the output is named after the model.\n",
    "\n",
    "Dependencies:  openai  |  pandas  |  pydantic  |  openpyxl\n",
    "\"\"\"\n",
    "\n",
    "# ─── 1. CONFIGURATION ────────────────────────────────────────────────────────\n",
    "INPUT_FILE  = \"archive/legacy_runs/lr_estimation_2025_07_21/est_lrs_by_disease.xlsx\"\n",
    "OUTPUT_FILE = \"archive/legacy_runs/lr_estimation_2025_07_21/est_lrs_by_disease_filled.xlsx\"\n",
    "\n",
    "# Provide one or many model IDs here.\n",
    "model_names = [\"o3-2025-04-16\"] #[\"gpt-4o-mini-2024-07-18\"] # \n",
    "\n",
    "# Optional: tune reasoning depth for o‑series models.\n",
    "REASONING_EFFORT = \"low\"   # \"low\" | \"medium\" | \"high\"\n",
    "\n",
    "\n",
    "# ─── 2. RESPONSE SCHEMA ──────────────────────────────────────────────────────\n",
    "class LRResponse(BaseModel):\n",
    "    value: float\n",
    "\n",
    "# ─── 3. PROMPT ───────────────────────────────────────────────────────────────\n",
    "LR_PROMPT_TEMPLATE = \"\"\"You are an expert in medical diagnosis who is giving assessments of how important a piece of information is when determining whether a patient has a particularly condition. \n",
    "Your task is to estimate the likelihood ratio of a finding for a disease. \n",
    "Recall that the likelihood ratio represents how much the ratio between the odds of disease given a result for a lab value, whether a physical exam finding is present, or whether a comorbidity is present over the odds of disease when you did not know the result.\n",
    "You will receive inputs in the following format; Target condition: <Condition, e.g. Patient Has: Cardiac chest pain>. Finding: <piece of information, e.g. ‘Patient does not have: radiation to the neck, arm, or jaw’>.\n",
    "So, for example. If the odds of a Condition Z being present was 1 (meaning 50% probability) before we knew anything, but then we got a result (Finding A) it became 2 (meaning 2:1 odds or 66% probability), then the likelihood ratio would be 2. \n",
    "Given a condition and a finding, you will provide your best estimate of the likelihood ratio as a floating point number. Return your answer in valid JSON with the following schema: { 'value': <floating point number greater than 0> }.\\n\\n\n",
    "\n",
    "Remember, stronger evidence in favor of a condition has a value farther above 1. Strong evidence against a diagnosis has a value farther below 1 (closer to 0). A likelihood ratio of 10 is equally strong evidence for a condition as a likelihood ratio of 0.1 is against it. Likelihood ratios near 1 represent weak evidence for or against. \n",
    "And if the \"patient does not have: \" some feature that is almost always present, that is strong evidence against.\n",
    "(pay attention for double negatives- 'Patient has: no tobacco use' and 'Patient does not have: tobacco use' are identical)\n",
    "\n",
    "Here is how I would like you to approach the problem:\n",
    "First, consider the condition you are predicting (Condition: ___). \n",
    "Is the condition a medical diagnosis? If so, what kind of findings are usually present in someone who has that condition. \n",
    "Does the condition specify a certain type of patient? If so, how does that change things? \n",
    "Then, consider the finding. \n",
    "If a finding is much more common among patients who have the condition of interest than among patients who do not have the condition of interest, then the likelihood ratio should be high. \n",
    "This might be because the finding is a consequence of the disease, indicates that an enabling condition is present, indicates that a frequently comorbid condition is present, or is related to the pathology of the condition. \n",
    "In general, likelihood ratios over about 20 are pathognomonic, above 5 or so is extremely strong evidence in favor, above 2.5 or so is strong evidence, above 1.4 is so-so evidence, and 1-1.4 is pretty weak evidence. \n",
    "Conversely, if the finding is more common in people who do NOT have the condition, then the likelihood ratio should be below 1. \n",
    "Similarly, a likelihood ratio below 0.05 would exclude the condition in most situations, below 0.2 would be extremely strong evidence against, below 0.4 would be strong evidence against, below 0.71 is so-so, and between 0.71 and 1 is pretty weak evidence against (meaning, it just doesn’t change the odds of the condition much). \n",
    "\n",
    "Here are some hypothetical examples to consider: \n",
    "    Prompt = Target condition: Cardiac Chest Pain. Finding: Patient has: Pain not worse with exertion (requires they clarify exercise 1hr after meal).\n",
    "    You would reason that because cardiac chest pain is usually worse with exertion because exertion worsens cardiac demand for oxygen, and thus worsens ischemia.\n",
    "    Response = {\n",
    "        ‘value’: 0.4\n",
    "    }\n",
    "\n",
    "    Prompt =  Target condition: Cardiac Chest Pain. Finding: Patient does not have: tobacco.\n",
    "    You would reason that because being someone who smokes increases your risk of coronary artery disease, and thus being a never smoker means you’re at less risk… but many people who have heart attacks still smoke, so it’s only a weak predictor. \n",
    "    Response = {\n",
    "        ‘value’: 0.75\n",
    "    }\n",
    "\n",
    "    Prompt = Target condition: Cardaic Chest Pain. Finding = Patient has: enjoys playing chess.\n",
    "    You would reason that because enjoying chest has no relationship to having a heart attack.\n",
    "    Response = {\n",
    "        ‘value’: 1\n",
    "    }\n",
    "\n",
    "    Prompt = Target condition: Cardiac Chest Pain. Finding = Patient has: pain located behind the sternum\n",
    "    You would reason that because cardiac chest pain is often experienced behind the sternum (thus, more likely), but so are many other causes of chest pain - like GERD.\n",
    "    Response = {\n",
    "        ‘value’: 1.2\n",
    "    }\n",
    "\n",
    "    Prompt = Condition: Cardiac Chest Pain. Finding = patient has: pain worse with exertion.\n",
    "    You would reason that because the increased myocardial oxygen consumption worsens the pain if oxygen delivery to the myocardium is the cause, as it is in heart attacks.\n",
    "    Response = {\n",
    "        ‘value’: 3.4\n",
    "    }\n",
    "\n",
    "    OK: here’s the prompt.. \"\"\"\n",
    "\n",
    "# ─── 4. LLM CALL ──────────────────────────────────────────────────────────────\n",
    "def estimate_lr(\n",
    "    disease: str,\n",
    "    finding: str,\n",
    "    client: OpenAI,\n",
    "    model: str,\n",
    ") -> float | str:\n",
    "    \"\"\"Return LR or 'ERROR'.\"\"\"\n",
    "    sys_msgs = [{\"role\": \"system\", \"content\": LR_PROMPT_TEMPLATE}]\n",
    "    user_msg = {\"role\": \"user\",\n",
    "                \"content\": f\"Condition: {disease}\\nFinding: {finding}\"}\n",
    "    kwargs: dict = {}\n",
    "    if model.startswith(\"o\"):\n",
    "        kwargs[\"reasoning_effort\"] = REASONING_EFFORT\n",
    "\n",
    "    print(f\"LLM call → model='{model}' | disease='{disease}' | finding='{finding}'\")\n",
    "\n",
    "    try:\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model=model,\n",
    "            messages=[*sys_msgs, user_msg],\n",
    "            response_format=LRResponse,\n",
    "            **kwargs,\n",
    "        )\n",
    "        return completion.choices[0].message.parsed.value\n",
    "    except Exception as exc:\n",
    "        print(f\"LLM error ({model}): {exc}\")\n",
    "        return \"ERROR\"\n",
    "\n",
    "# ─── 5. MATRIX FILL ──────────────────────────────────────────────────────────\n",
    "def fill_matrix(df: pd.DataFrame, model: str, client: OpenAI) -> pd.DataFrame:\n",
    "    \"\"\"Return copy of df with blank cells filled for one model.\"\"\"\n",
    "    # Trim truly empty columns first (Excel “used‑range” artefacts)\n",
    "    df = df.loc[:, ~(df.replace(\"\", pd.NA).isna().all())].copy()\n",
    "\n",
    "    # Identify diseases in row‑0 (skip col‑0).\n",
    "    diseases = {\n",
    "        col: str(df.iloc[0, col]).strip()\n",
    "        for col in range(1, df.shape[1])\n",
    "        if pd.notna(df.iloc[0, col]) and str(df.iloc[0, col]).strip()\n",
    "    }\n",
    "    if not diseases:\n",
    "        raise ValueError(\"No disease headers found in row 0.\")\n",
    "\n",
    "    # Iterate through findings (rows ≥1) × diseases.\n",
    "    for row in range(1, df.shape[0]):\n",
    "        finding = df.iloc[row, 0]\n",
    "        if pd.isna(finding) or not str(finding).strip():\n",
    "            continue                                          # skip blank rows\n",
    "        for col, disease in diseases.items():\n",
    "            if pd.isna(df.iat[row, col]) or df.iat[row, col] == \"\":\n",
    "                lr = estimate_lr(disease, finding, client, model)\n",
    "                df.iat[row, col] = lr\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecad58a",
   "metadata": {},
   "source": [
    "#### Non plus-minus version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f3b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 6. DRIVER ───────────────────────────────────────────────────────────────\n",
    "def main() -> None:\n",
    "    df0 = pd.read_excel(INPUT_FILE, sheet_name=0, header=None)\n",
    "\n",
    "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "    with pd.ExcelWriter(OUTPUT_FILE, engine=\"openpyxl\") as writer:\n",
    "        if len(model_names) == 1:\n",
    "            fill_matrix(df0, model_names[0], client) \\\n",
    "                .to_excel(writer, sheet_name=\"LRs\", index=False, header=False)\n",
    "        else:\n",
    "            for m in model_names:\n",
    "                fill_matrix(df0, m, client) \\\n",
    "                    .to_excel(writer, sheet_name=m, index=False, header=False)\n",
    "    print(f\"Completed workbook saved → {OUTPUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5165c884",
   "metadata": {},
   "source": [
    "## Plus-Minus Diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e36ae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# PLUS‑MINUS  D I S E A S E S\n",
    "# ---------------------------------------------------------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "INPUT_PM_DIS  = \"archive/legacy_runs/lr_estimation_2025_07_21/est_lrs_by_disease_for_plusminus.xlsx\"\n",
    "OUTPUT_PM_DIS = \"archive/legacy_runs/lr_estimation_2025_07_21/est_lrs_by_disease_plusminus_filled.xlsx\"\n",
    "\n",
    "# Uses the `model_names`, `estimate_lr`, and `fill_matrix`\n",
    "# from the “Reasoning about Diseases” section.\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "def build_plusminus_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Duplicate every finding into 'has' / 'does not have' variants.\"\"\"\n",
    "    header = df.iloc[0].copy()\n",
    "    findings = df.iloc[1:, 0].dropna().astype(str).str.strip()\n",
    "\n",
    "    pm_rows = []\n",
    "    for f in findings:\n",
    "        low = f.lower()\n",
    "        if low.startswith(\"patient has:\") or low.startswith(\"patient does not have:\"):\n",
    "            pm_rows.append(f)\n",
    "        else:\n",
    "            pm_rows.append(f\"Patient has: {f}\")\n",
    "            pm_rows.append(f\"Patient does not have: {f}\")\n",
    "\n",
    "    df_pm = pd.DataFrame(\n",
    "        \"\",\n",
    "        index=range(len(pm_rows) + 1),\n",
    "        columns=df.columns,\n",
    "    )\n",
    "    df_pm.iloc[0] = header\n",
    "    df_pm.iloc[1:, 0] = pm_rows\n",
    "\n",
    "    return df_pm.loc[:, ~(df_pm.replace(\"\", pd.NA).isna().all())]\n",
    "\n",
    "\n",
    "# ––– LOAD, EXPAND, RUN –––––––––––––––––––––––––––––––––––––––––––––––––––––––\n",
    "df_orig = pd.read_excel(INPUT_PM_DIS, sheet_name=0, header=None)\n",
    "df_plusminus = build_plusminus_df(df_orig)\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "with pd.ExcelWriter(OUTPUT_PM_DIS, engine=\"openpyxl\") as writer:\n",
    "    if len(model_names) == 1:\n",
    "        fill_matrix(df_plusminus, model_names[0], client) \\\n",
    "            .to_excel(writer, sheet_name=\"LRs\", index=False, header=False)\n",
    "    else:\n",
    "        for m in model_names:\n",
    "            fill_matrix(df_plusminus, m, client) \\\n",
    "                .to_excel(writer, sheet_name=m, index=False, header=False)\n",
    "\n",
    "print(f\"✔  Plus‑minus (diseases) workbook saved → {OUTPUT_PM_DIS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f438ff",
   "metadata": {},
   "source": [
    "## Discriminitave LRs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16daac18",
   "metadata": {},
   "source": [
    "#### General, differential likelihood ratio estimators\n",
    "\n",
    "This answers the question: in general, what are the features that differentiate between Disease A and Disease B. (not specific to a particular case)\n",
    "\n",
    "Inputs: Correct diagnosis, learner’s differential, and transcript.\n",
    "\n",
    "Outputs: A list of key evidence that differentiates cases where the learner’s differential diagnosis was correct vs. the actual correct diagnosis.\n",
    "\n",
    "Challenges:\n",
    "- Learners may list many possible diagnoses, requiring feedback across a broad range.\n",
    "- Usefulness is measured by differential LR (A vs. B) rather than the usual (overall) LR (A vs. not A).\n",
    "\n",
    "Approach:\n",
    "- Collected all DDx from Cory's list; in production, this can be auto-extracted from the transcript.\n",
    "- Used GPT-4o to identify key discriminating factors in:\n",
    "\t- HPI, Context (Medical, Surgical, Medications, Social, Family), Vitals/Exam, and Testing.\n",
    "- In production, we’d automate detecting whether the learner asked about these factors and generate feedback:\n",
    "\t- “X was important, and you asked it.”\n",
    "\t- “Y was important, but you didn’t ask it.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da551c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Differential-LR estimation for every finding row\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# 1.  Prompt helpers \n",
    "\n",
    "def generate_diff_gen_prompt(\n",
    "    dx_cat_1: str,\n",
    "    dx_cat_2: str,\n",
    "    dx_cat_1_examples: list[str],\n",
    "    dx_cat_2_examples: list[str],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Build a structured prompt for an LLM to estimate the *differential*\n",
    "    likelihood ratio between two diagnosis categories.  Each category\n",
    "    is augmented with illustrative exemplar diseases to reinforce the\n",
    "    desired clinical context (few‑shot cueing).\n",
    "    \"\"\"\n",
    "    # helper to format the exemplar list as comma‑separated text\n",
    "    def fmt_examples(ex_list: list[str]) -> str:\n",
    "        return \", \".join(ex_list) if ex_list else \"—\"\n",
    "\n",
    "    ex1 = fmt_examples(dx_cat_1_examples)\n",
    "    ex2 = fmt_examples(dx_cat_2_examples)\n",
    "\n",
    "    return f\"\"\"\n",
    "Your task: Estimate the **likelihood ratio (LR)** for a clinical finding\n",
    "that discriminates **{dx_cat_1}** from **{dx_cat_2}** in an outpatient\n",
    "chest‑pain evaluation.  Assume the patient has **exactly one** of these\n",
    "two conditions; other diagnoses can be ignored.\n",
    "\n",
    "**Category examples**  \n",
    "• {dx_cat_1}: {ex1}  \n",
    "• {dx_cat_2}: {ex2}\n",
    "\n",
    "### Working definition\n",
    "LR = P(finding | {dx_cat_1}) ÷ P(finding | {dx_cat_2})\n",
    "\n",
    "### Qualitative bands (reference only)\n",
    "* LR > 10 strong evidence for {dx_cat_1}  \n",
    "* 5 < LR ≤ 10 moderate evidence for {dx_cat_1}  \n",
    "* 2 < LR ≤ 5 weak evidence for {dx_cat_1}  \n",
    "* 0.5 < LR ≤ 2 negligible evidence  \n",
    "* 0.2 < LR ≤ 0.5 weak evidence for {dx_cat_2}  \n",
    "* 0.1 < LR ≤ 0.2 moderate evidence for {dx_cat_2}  \n",
    "* LR ≤ 0.1 strong evidence for {dx_cat_2}\n",
    "\n",
    "### Response format (JSON, one line)\t\n",
    "{{“lr”: , “strength”: “”, “rationale”: “<≤40 words>”}}\n",
    "Only output the JSON block—no extra text.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_dx_categories(path: str):\n",
    "    \"\"\"\n",
    "    Parse the workbook where row‑0 contains sparse category labels and\n",
    "    row‑1 lists exemplar diseases.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dx_cat_1, dx_cat_2       : str\n",
    "    dx_cat_1_examples        : list[str]\n",
    "    dx_cat_2_examples        : list[str]\n",
    "    \"\"\"\n",
    "    # read raw without header inference\n",
    "    df_raw = pd.read_excel(Path(path), header=None)\n",
    "\n",
    "    # first row → categories; forward‑fill missing cells\n",
    "    cats = df_raw.iloc[0].ffill()\n",
    "\n",
    "    # second row → exemplar diseases (may contain NaN)\n",
    "    ex_row = df_raw.iloc[1]\n",
    "\n",
    "    # identify distinct category names in order of appearance\n",
    "    unique_cats = pd.unique(cats.dropna())\n",
    "    if len(unique_cats) != 2:\n",
    "        raise ValueError(\"Expected exactly two category labels in first row\")\n",
    "\n",
    "    dx_cat_1, dx_cat_2 = unique_cats.tolist()\n",
    "\n",
    "    # build example lists aligned with column categories\n",
    "    dx_cat_1_examples = ex_row[cats == dx_cat_1].dropna().astype(str).tolist()\n",
    "    dx_cat_2_examples = ex_row[cats == dx_cat_2].dropna().astype(str).tolist()\n",
    "\n",
    "    return dx_cat_1, dx_cat_2, dx_cat_1_examples, dx_cat_2_examples\n",
    "\n",
    "# ---------- response schema -------------------------------------------------\n",
    "class DiffLR(BaseModel):\n",
    "    lr: float\n",
    "    strength: str\n",
    "    rationale: str\n",
    "\n",
    "# ---------- single LLM call -------------------------------------------------\n",
    "def estimate_diff_lr(\n",
    "    finding: str,\n",
    "    dx_cat_1: str,\n",
    "    dx_cat_2: str,\n",
    "    ex1: list[str],\n",
    "    ex2: list[str],\n",
    "    model: str = \"gpt-5-mini\",\n",
    "    reasoning_effort: str = \"medium\",\n",
    "    client: OpenAI | None = None,\n",
    ") -> float | str:\n",
    "    if client is None:\n",
    "        client = OpenAI()\n",
    "\n",
    "    prompt = generate_diff_gen_prompt(dx_cat_1, dx_cat_2, ex1, ex2)\n",
    "\n",
    "    sys_msg  = {\"role\": \"system\", \"content\": prompt}\n",
    "    user_msg = {\"role\": \"user\",  \"content\": f\"Finding: {finding}\"}\n",
    "\n",
    "    kwargs = {}\n",
    "    if model.startswith(\"o\"):\n",
    "        kwargs[\"reasoning_effort\"] = reasoning_effort\n",
    "\n",
    "    try:\n",
    "        resp = client.beta.chat.completions.parse(\n",
    "            model=model,\n",
    "            messages=[sys_msg, user_msg],\n",
    "            response_format=DiffLR,\n",
    "            **kwargs,\n",
    "        )\n",
    "        return resp.choices[0].message.parsed.lr\n",
    "    except Exception as exc:\n",
    "        print(f\"LLM error for finding '{finding}': {exc}\")\n",
    "        return \"ERROR\"\n",
    "\n",
    "# 2.  File paths --------------------------------------------------------------\n",
    "#WB_IN  = Path('archive/legacy_runs/lr_estimation_2025_07_21/LRs for 87 features within GI ddx - dysphagia vs esophageal pain without dysphagia.xlsx')\n",
    "#WB_OUT = Path('archive/legacy_runs/lr_estimation_2025_07_21/LRs for 87 features within GI ddx - dysphagia vs esophageal pain without dysphagia_filled.xlsx')\n",
    "WB_IN = Path('archive/legacy_runs/lr_estimation_2025_07_21/LRs for 87 features within GI ddx - dysphagia vs esophageal pain without dysphagia.xlsx')\n",
    "WB_OUT = Path('archive/legacy_runs/lr_estimation_2025_07_21/LRs for 87 features within GI ddx - dysphagia vs esophageal pain without dysphagia_filled.xlsx')\n",
    "MODEL_ID = \"gpt-5-mini\"\n",
    "\n",
    "# 3.  Load categories & examples ---------------------------------------------\n",
    "dx_cat_1, dx_cat_2, ex1, ex2 = load_dx_categories(WB_IN)\n",
    "\n",
    "# 4.  Read sheet and append results column -----------------------------------\n",
    "df = pd.read_excel(WB_IN, sheet_name=0, header=None)\n",
    "df_out = df.copy()\n",
    "\n",
    "result_col = df_out.shape[1]      # index for new column\n",
    "df_out[result_col] = np.nan       # create the column\n",
    "\n",
    "header_label = (\n",
    "    f\"Differential LR ({MODEL_ID} for '{dx_cat_1}' vs. '{dx_cat_2}')\"\n",
    ")\n",
    "df_out.iat[0, result_col] = header_label       # descriptive header\n",
    "df_out.iat[1, result_col] = \"\"                 # keep exemplar row blank\n",
    "\n",
    "\n",
    "# 5.  Iterate over findings (rows ≥ 2) ---------------------------------------\n",
    "client = OpenAI()\n",
    "total_rows = df_out.shape[0] - 2           # rows of actual findings\n",
    "done = 0\n",
    "\n",
    "for row in range(2, df_out.shape[0]):\n",
    "    finding = str(df_out.iat[row, 0]).strip()\n",
    "    if not finding:\n",
    "        continue\n",
    "\n",
    "    done += 1\n",
    "    print(f\"[{done}/{total_rows}] Estimating LR for: {finding[:60]}\")\n",
    "\n",
    "    lr_val = estimate_diff_lr(\n",
    "        finding=finding,\n",
    "        dx_cat_1=dx_cat_1,\n",
    "        dx_cat_2=dx_cat_2,\n",
    "        ex1=ex1,\n",
    "        ex2=ex2,\n",
    "        model=MODEL_ID,\n",
    "        reasoning_effort=\"medium\",\n",
    "        client=client,\n",
    "    )\n",
    "    df_out.iat[row, result_col] = lr_val\n",
    "\n",
    "# 6.  Save workbook -----------------------------------------------------------\n",
    "df_out.to_excel(WB_OUT, index=False, header=False)\n",
    "print(f\"Saved filled sheet to {WB_OUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6a27f5",
   "metadata": {},
   "source": [
    "New version for GPT-5 interface. Note, might be fine to just use low (rather than medium) reasoning. \n",
    "\n",
    "Note that this requires some set up: needs separate notebooks that have: \n",
    "- row 1 contains the categories, spaced such that examples are in the next row and continue until the next category\n",
    "- note, only allows 2 categories for now - if needed, coudl generalize this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a83df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Differential-LR estimation for every finding row — GPT-5 + Responses API only\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "from __future__ import annotations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "\n",
    "# =============================================================================\n",
    "# 1) Prompt helpers\n",
    "# =============================================================================\n",
    "\n",
    "def generate_diff_gen_prompt(\n",
    "    dx_cat_1: str,\n",
    "    dx_cat_2: str,\n",
    "    dx_cat_1_examples: list[str],\n",
    "    dx_cat_2_examples: list[str],\n",
    ") -> str:\n",
    "    \"\"\"Concise prompt; schema enforcement is via Structured Outputs.\"\"\"\n",
    "    def fmt_examples(ex_list: list[str]) -> str:\n",
    "        return \", \".join(ex_list) if ex_list else \"—\"\n",
    "\n",
    "    ex1 = fmt_examples(dx_cat_1_examples)\n",
    "    ex2 = fmt_examples(dx_cat_2_examples)\n",
    "\n",
    "    return f\"\"\"\n",
    "You are a clinical epidemiologist.\n",
    "\n",
    "Task: Estimate the *differential* likelihood ratio (LR) for a single clinical finding\n",
    "that discriminates **{dx_cat_1}** from **{dx_cat_2}** in an outpatient chest-pain evaluation.\n",
    "Assume the patient has exactly one of these two conditions.\n",
    "\n",
    "Category examples:\n",
    "• {dx_cat_1}: {ex1}\n",
    "• {dx_cat_2}: {ex2}\n",
    "\n",
    "Definition\n",
    "LR = P(finding | {dx_cat_1}) / P(finding | {dx_cat_2})\n",
    "\n",
    "Reference bands (for interpreting strength):\n",
    ">10 strong for {dx_cat_1}; 5–10 moderate; 2–5 weak; 0.5–2 negligible;\n",
    "0.2–0.5 weak for {dx_cat_2}; 0.1–0.2 moderate; ≤0.1 strong for {dx_cat_2}.\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def load_dx_categories(path: str | Path):\n",
    "    \"\"\"\n",
    "    Workbook: row 0 has sparse category labels; row 1 lists exemplars.\n",
    "    Returns: dx_cat_1, dx_cat_2, dx_cat_1_examples, dx_cat_2_examples\n",
    "    \"\"\"\n",
    "    df_raw = pd.read_excel(Path(path), header=None)\n",
    "    cats   = df_raw.iloc[0].ffill()\n",
    "    ex_row = df_raw.iloc[1]\n",
    "\n",
    "    unique_cats = pd.unique(cats.dropna())\n",
    "    if len(unique_cats) != 2:\n",
    "        raise ValueError(\"Expected exactly two category labels in row 0.\")\n",
    "\n",
    "    dx_cat_1, dx_cat_2 = unique_cats.tolist()\n",
    "    ex1 = ex_row[cats == dx_cat_1].dropna().astype(str).tolist()\n",
    "    ex2 = ex_row[cats == dx_cat_2].dropna().astype(str).tolist()\n",
    "    return dx_cat_1, dx_cat_2, ex1, ex2\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2) Structured Outputs schema (Pydantic)\n",
    "# =============================================================================\n",
    "\n",
    "class DiffLR(BaseModel):\n",
    "    lr: float        # positive real number\n",
    "    strength: str | None = None\n",
    "    rationale: str | None = None\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3) Single call via Responses API (Structured Outputs)\n",
    "# =============================================================================\n",
    "\n",
    "MODEL_ID         = \"gpt-5\"     # or \"gpt-5-mini\"\n",
    "REASONING_EFFORT = \"high\"   # minimal | low | medium | high\n",
    "VERBOSITY        = \"low\"       # optional brevity control\n",
    "\n",
    "client = OpenAI()  # Requires OPENAI_API_KEY in env\n",
    "\n",
    "def estimate_diff_lr(\n",
    "    finding: str,\n",
    "    dx_cat_1: str,\n",
    "    dx_cat_2: str,\n",
    "    ex1: list[str],\n",
    "    ex2: list[str],\n",
    ") -> float | str:\n",
    "    \"\"\"\n",
    "    Call GPT-5 Responses API once for a single finding; return numeric LR or \"ERROR\".\n",
    "    \"\"\"\n",
    "    prompt = generate_diff_gen_prompt(dx_cat_1, dx_cat_2, ex1, ex2)\n",
    "\n",
    "    try:\n",
    "        # Role-style input items, parsed directly into Pydantic\n",
    "        resp = client.responses.parse(\n",
    "            model=MODEL_ID,\n",
    "            input=[\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\",   \"content\": f\"Finding: {finding}\"},\n",
    "            ],\n",
    "            text_format=DiffLR,                # Structured Outputs → Pydantic\n",
    "            reasoning={\"effort\": REASONING_EFFORT},\n",
    "            text={\"verbosity\": VERBOSITY},\n",
    "            # NOTE: do not pass temperature/top_p for reasoning models\n",
    "        )\n",
    "        return float(resp.output_parsed.lr)\n",
    "    except Exception as exc:\n",
    "        print(f\"LLM error for finding '{finding}': {exc}\")\n",
    "        return \"ERROR\"\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4) I/O paths\n",
    "# =============================================================================\n",
    "\n",
    "WB_IN  = Path('archive/legacy_runs/lr_estimation_2025_07_21/'\n",
    "             'LRs for 87 features within GI ddx - dysphagia vs esophageal pain without dysphagia.xlsx')\n",
    "\n",
    "WB_OUT = Path('archive/legacy_runs/lr_estimation_2025_07_21/'\n",
    "             'LRs for 87 features within GI ddx - dysphagia vs esophageal pain without dysphagia_filled.xlsx')\n",
    "\n",
    "#WB_IN  = Path('archive/legacy_runs/lr_estimation_2025_07_21/'\n",
    "#              'LRs for 87 features within esophageal dysphagia ddx - nonprogressive vs progressive.xlsx')\n",
    "#\n",
    "#WB_OUT = Path('archive/legacy_runs/lr_estimation_2025_07_21/'\n",
    "#              'LRs for 87 features within esophageal dysphagia ddx - nonprogressive vs progressive_filled.xlsx')\n",
    "\n",
    "#WB_IN  = Path('archive/legacy_runs/lr_estimation_2025_07_21/'\n",
    "#              'LRs for 87 features within esoph dysmotility non-progressive dysphgia ddx - w or wo autoimmune.xlsx')\n",
    "#\n",
    "#WB_OUT = Path('archive/legacy_runs/lr_estimation_2025_07_21/'\n",
    "#              'LRs for 87 features within esoph dysmotility non-progressive dysphgia ddx - w or wo autoimmune_filled.xlsx')\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 5) Main sheet logic\n",
    "# =============================================================================\n",
    "\n",
    "# Load diagnostic categories & exemplars (rows 0–1)\n",
    "dx_cat_1, dx_cat_2, ex1, ex2 = load_dx_categories(WB_IN)\n",
    "\n",
    "# Read sheet and append results column (ensure object dtype to avoid warnings)\n",
    "df     = pd.read_excel(WB_IN, sheet_name=0, header=None)\n",
    "df_out = df.copy()\n",
    "\n",
    "result_col = df_out.shape[1]\n",
    "df_out[result_col] = pd.Series([None] * len(df_out), dtype=\"object\")\n",
    "\n",
    "header_label = f\"Differential LR ({MODEL_ID} for '{dx_cat_1}' vs. '{dx_cat_2}')\"\n",
    "df_out.iat[0, result_col] = header_label\n",
    "df_out.iat[1, result_col] = \"\"  # keep exemplar row blank\n",
    "\n",
    "# Iterate findings (rows ≥ 2) with progress\n",
    "total_rows = df_out.shape[0] - 2\n",
    "done = 0\n",
    "\n",
    "for row in range(2, df_out.shape[0]):\n",
    "    finding = str(df_out.iat[row, 0]).strip()\n",
    "    if not finding:\n",
    "        continue\n",
    "\n",
    "    done += 1\n",
    "    print(f\"[{done}/{total_rows}] Estimating LR for: {finding[:60]}\")\n",
    "\n",
    "    lr_val = estimate_diff_lr(\n",
    "        finding=finding,\n",
    "        dx_cat_1=dx_cat_1,\n",
    "        dx_cat_2=dx_cat_2,\n",
    "        ex1=ex1,\n",
    "        ex2=ex2,\n",
    "    )\n",
    "    df_out.iat[row, result_col] = lr_val\n",
    "\n",
    "# Save\n",
    "df_out.to_excel(WB_OUT, index=False, header=False)\n",
    "print(f\"\\nCompleted. Filled sheet saved to {WB_OUT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa5820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Differential-LR estimation for every finding row — GPT-5 + Responses API only\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "from __future__ import annotations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "\n",
    "# =============================================================================\n",
    "# 1) Prompt helpers\n",
    "# =============================================================================\n",
    "\n",
    "def generate_diff_gen_prompt(\n",
    "    dx_cat_1: str,\n",
    "    dx_cat_2: str,\n",
    "    dx_cat_1_examples: list[str],\n",
    "    dx_cat_2_examples: list[str],\n",
    ") -> str:\n",
    "    \"\"\"Concise prompt; schema enforcement is via Structured Outputs.\"\"\"\n",
    "    def fmt_examples(ex_list: list[str]) -> str:\n",
    "        return \", \".join(ex_list) if ex_list else \"—\"\n",
    "\n",
    "    ex1 = fmt_examples(dx_cat_1_examples)\n",
    "    ex2 = fmt_examples(dx_cat_2_examples)\n",
    "\n",
    "    return f\"\"\"\n",
    "You are a clinical epidemiologist.\n",
    "\n",
    "Task: Estimate the *differential* likelihood ratio (LR) for a single clinical finding\n",
    "that discriminates **{dx_cat_1}** from **{dx_cat_2}** in an outpatient chest-pain evaluation.\n",
    "Assume the patient has exactly one of these two conditions.\n",
    "\n",
    "Category examples:\n",
    "• {dx_cat_1}: {ex1}\n",
    "• {dx_cat_2}: {ex2}\n",
    "\n",
    "Definition\n",
    "LR = P(finding | {dx_cat_1}) / P(finding | {dx_cat_2})\n",
    "\n",
    "Reference bands (for interpreting strength):\n",
    ">10 strong for {dx_cat_1}; 5–10 moderate; 2–5 weak; 0.5–2 negligible;\n",
    "0.2–0.5 weak for {dx_cat_2}; 0.1–0.2 moderate; ≤0.1 strong for {dx_cat_2}.\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def load_dx_categories(path: str | Path):\n",
    "    \"\"\"\n",
    "    Workbook: row 0 has sparse category labels; row 1 lists exemplars.\n",
    "    Returns: dx_cat_1, dx_cat_2, dx_cat_1_examples, dx_cat_2_examples\n",
    "    \"\"\"\n",
    "    df_raw = pd.read_excel(Path(path), header=None)\n",
    "    cats   = df_raw.iloc[0].ffill()\n",
    "    ex_row = df_raw.iloc[1]\n",
    "\n",
    "    unique_cats = pd.unique(cats.dropna())\n",
    "    if len(unique_cats) != 2:\n",
    "        raise ValueError(\"Expected exactly two category labels in row 0.\")\n",
    "\n",
    "    dx_cat_1, dx_cat_2 = unique_cats.tolist()\n",
    "    ex1 = ex_row[cats == dx_cat_1].dropna().astype(str).tolist()\n",
    "    ex2 = ex_row[cats == dx_cat_2].dropna().astype(str).tolist()\n",
    "    return dx_cat_1, dx_cat_2, ex1, ex2\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2) Structured Outputs schema (Pydantic)\n",
    "# =============================================================================\n",
    "\n",
    "class DiffLR(BaseModel):\n",
    "    lr: float        # positive real number\n",
    "    strength: str | None = None\n",
    "    rationale: str | None = None\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3) Single call via Responses API (Structured Outputs)\n",
    "# =============================================================================\n",
    "\n",
    "MODEL_ID         = \"gpt-5\"     # or \"gpt-5-mini\"\n",
    "REASONING_EFFORT = \"medium\"   # minimal | low | medium | high\n",
    "VERBOSITY        = \"low\"       # optional brevity control\n",
    "\n",
    "client = OpenAI()  # Requires OPENAI_API_KEY in env\n",
    "\n",
    "def estimate_diff_lr(\n",
    "    finding: str,\n",
    "    dx_cat_1: str,\n",
    "    dx_cat_2: str,\n",
    "    ex1: list[str],\n",
    "    ex2: list[str],\n",
    ") -> float | str:\n",
    "    \"\"\"\n",
    "    Call GPT-5 Responses API once for a single finding; return numeric LR or \"ERROR\".\n",
    "    \"\"\"\n",
    "    prompt = generate_diff_gen_prompt(dx_cat_1, dx_cat_2, ex1, ex2)\n",
    "\n",
    "    try:\n",
    "        # Role-style input items, parsed directly into Pydantic\n",
    "        resp = client.responses.parse(\n",
    "            model=MODEL_ID,\n",
    "            input=[\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\",   \"content\": f\"Finding: {finding}\"},\n",
    "            ],\n",
    "            text_format=DiffLR,                # Structured Outputs → Pydantic\n",
    "            reasoning={\"effort\": REASONING_EFFORT},\n",
    "            text={\"verbosity\": VERBOSITY},\n",
    "            # NOTE: do not pass temperature/top_p for reasoning models\n",
    "        )\n",
    "        return float(resp.output_parsed.lr)\n",
    "    except Exception as exc:\n",
    "        print(f\"LLM error for finding '{finding}': {exc}\")\n",
    "        return \"ERROR\"\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4) I/O paths\n",
    "# =============================================================================\n",
    "\n",
    "#WB_IN  = Path('archive/legacy_runs/lr_estimation_2025_07_21/'\n",
    "#             'LRs for 87 features within GI ddx - dysphagia vs esophageal pain without dysphagia.xlsx')\n",
    "\n",
    "#WB_OUT = Path('archive/legacy_runs/lr_estimation_2025_07_21/'\n",
    "#             'LRs for 87 features within GI ddx - dysphagia vs esophageal pain without dysphagia_filled.xlsx')\n",
    "\n",
    "\n",
    "WB_IN  = Path('archive/legacy_runs/lr_estimation_2025_07_21/'\n",
    "              'LRs for 87 features within esophageal dysphagia ddx - nonprogressive vs progressive.xlsx')\n",
    "\n",
    "WB_OUT = Path('archive/legacy_runs/lr_estimation_2025_07_21/'\n",
    "              'LRs for 87 features within esophageal dysphagia ddx - nonprogressive vs progressive_filled.xlsx')\n",
    "\n",
    "#WB_IN  = Path('archive/legacy_runs/lr_estimation_2025_07_21/'\n",
    "#              'LRs for 87 features within esoph dysmotility non-progressive dysphgia ddx - w or wo autoimmune.xlsx')\n",
    "#\n",
    "#WB_OUT = Path('archive/legacy_runs/lr_estimation_2025_07_21/'\n",
    "#              'LRs for 87 features within esoph dysmotility non-progressive dysphgia ddx - w or wo autoimmune_filled.xlsx')\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 5) Main sheet logic\n",
    "# =============================================================================\n",
    "\n",
    "# Load diagnostic categories & exemplars (rows 0–1)\n",
    "dx_cat_1, dx_cat_2, ex1, ex2 = load_dx_categories(WB_IN)\n",
    "\n",
    "# Read sheet and append results column (ensure object dtype to avoid warnings)\n",
    "df     = pd.read_excel(WB_IN, sheet_name=0, header=None)\n",
    "df_out = df.copy()\n",
    "\n",
    "result_col = df_out.shape[1]\n",
    "df_out[result_col] = pd.Series([None] * len(df_out), dtype=\"object\")\n",
    "\n",
    "header_label = f\"Differential LR ({MODEL_ID} for '{dx_cat_1}' vs. '{dx_cat_2}')\"\n",
    "df_out.iat[0, result_col] = header_label\n",
    "df_out.iat[1, result_col] = \"\"  # keep exemplar row blank\n",
    "\n",
    "# Iterate findings (rows ≥ 2) with progress\n",
    "total_rows = df_out.shape[0] - 2\n",
    "done = 0\n",
    "\n",
    "for row in range(2, df_out.shape[0]):\n",
    "    finding = str(df_out.iat[row, 0]).strip()\n",
    "    if not finding:\n",
    "        continue\n",
    "\n",
    "    done += 1\n",
    "    print(f\"[{done}/{total_rows}] Estimating LR for: {finding[:60]}\")\n",
    "\n",
    "    lr_val = estimate_diff_lr(\n",
    "        finding=finding,\n",
    "        dx_cat_1=dx_cat_1,\n",
    "        dx_cat_2=dx_cat_2,\n",
    "        ex1=ex1,\n",
    "        ex2=ex2,\n",
    "    )\n",
    "    df_out.iat[row, result_col] = lr_val\n",
    "\n",
    "# Save\n",
    "df_out.to_excel(WB_OUT, index=False, header=False)\n",
    "print(f\"\\nCompleted. Filled sheet saved to {WB_OUT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70188105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Differential-LR estimation for every finding row — GPT-5 + Responses API only\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "from __future__ import annotations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "\n",
    "# =============================================================================\n",
    "# 1) Prompt helpers\n",
    "# =============================================================================\n",
    "\n",
    "def generate_diff_gen_prompt(\n",
    "    dx_cat_1: str,\n",
    "    dx_cat_2: str,\n",
    "    dx_cat_1_examples: list[str],\n",
    "    dx_cat_2_examples: list[str],\n",
    ") -> str:\n",
    "    \"\"\"Concise prompt; schema enforcement is via Structured Outputs.\"\"\"\n",
    "    def fmt_examples(ex_list: list[str]) -> str:\n",
    "        return \", \".join(ex_list) if ex_list else \"—\"\n",
    "\n",
    "    ex1 = fmt_examples(dx_cat_1_examples)\n",
    "    ex2 = fmt_examples(dx_cat_2_examples)\n",
    "\n",
    "    return f\"\"\"\n",
    "You are a clinical epidemiologist.\n",
    "\n",
    "Task: Estimate the *differential* likelihood ratio (LR) for a single clinical finding\n",
    "that discriminates **{dx_cat_1}** from **{dx_cat_2}** in an outpatient chest-pain evaluation.\n",
    "Assume the patient has exactly one of these two conditions.\n",
    "\n",
    "Category examples:\n",
    "• {dx_cat_1}: {ex1}\n",
    "• {dx_cat_2}: {ex2}\n",
    "\n",
    "Definition\n",
    "LR = P(finding | {dx_cat_1}) / P(finding | {dx_cat_2})\n",
    "\n",
    "Reference bands (for interpreting strength):\n",
    ">10 strong for {dx_cat_1}; 5–10 moderate; 2–5 weak; 0.5–2 negligible;\n",
    "0.2–0.5 weak for {dx_cat_2}; 0.1–0.2 moderate; ≤0.1 strong for {dx_cat_2}.\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def load_dx_categories(path: str | Path):\n",
    "    \"\"\"\n",
    "    Workbook: row 0 has sparse category labels; row 1 lists exemplars.\n",
    "    Returns: dx_cat_1, dx_cat_2, dx_cat_1_examples, dx_cat_2_examples\n",
    "    \"\"\"\n",
    "    df_raw = pd.read_excel(Path(path), header=None)\n",
    "    cats   = df_raw.iloc[0].ffill()\n",
    "    ex_row = df_raw.iloc[1]\n",
    "\n",
    "    unique_cats = pd.unique(cats.dropna())\n",
    "    if len(unique_cats) != 2:\n",
    "        raise ValueError(\"Expected exactly two category labels in row 0.\")\n",
    "\n",
    "    dx_cat_1, dx_cat_2 = unique_cats.tolist()\n",
    "    ex1 = ex_row[cats == dx_cat_1].dropna().astype(str).tolist()\n",
    "    ex2 = ex_row[cats == dx_cat_2].dropna().astype(str).tolist()\n",
    "    return dx_cat_1, dx_cat_2, ex1, ex2\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 2) Structured Outputs schema (Pydantic)\n",
    "# =============================================================================\n",
    "\n",
    "class DiffLR(BaseModel):\n",
    "    lr: float        # positive real number\n",
    "    strength: str | None = None\n",
    "    rationale: str | None = None\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 3) Single call via Responses API (Structured Outputs)\n",
    "# =============================================================================\n",
    "\n",
    "MODEL_ID         = \"gpt-5\"     # or \"gpt-5-mini\"\n",
    "REASONING_EFFORT = \"medium\"   # minimal | low | medium | high\n",
    "VERBOSITY        = \"low\"       # optional brevity control\n",
    "\n",
    "client = OpenAI()  # Requires OPENAI_API_KEY in env\n",
    "\n",
    "def estimate_diff_lr(\n",
    "    finding: str,\n",
    "    dx_cat_1: str,\n",
    "    dx_cat_2: str,\n",
    "    ex1: list[str],\n",
    "    ex2: list[str],\n",
    ") -> float | str:\n",
    "    \"\"\"\n",
    "    Call GPT-5 Responses API once for a single finding; return numeric LR or \"ERROR\".\n",
    "    \"\"\"\n",
    "    prompt = generate_diff_gen_prompt(dx_cat_1, dx_cat_2, ex1, ex2)\n",
    "\n",
    "    try:\n",
    "        # Role-style input items, parsed directly into Pydantic\n",
    "        resp = client.responses.parse(\n",
    "            model=MODEL_ID,\n",
    "            input=[\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\",   \"content\": f\"Finding: {finding}\"},\n",
    "            ],\n",
    "            text_format=DiffLR,                # Structured Outputs → Pydantic\n",
    "            reasoning={\"effort\": REASONING_EFFORT},\n",
    "            text={\"verbosity\": VERBOSITY},\n",
    "            # NOTE: do not pass temperature/top_p for reasoning models\n",
    "        )\n",
    "        return float(resp.output_parsed.lr)\n",
    "    except Exception as exc:\n",
    "        print(f\"LLM error for finding '{finding}': {exc}\")\n",
    "        return \"ERROR\"\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 4) I/O paths\n",
    "# =============================================================================\n",
    "\n",
    "#WB_IN  = Path('archive/legacy_runs/lr_estimation_2025_07_21/'\n",
    "#             'LRs for 87 features within GI ddx - dysphagia vs esophageal pain without dysphagia.xlsx')\n",
    "\n",
    "#WB_OUT = Path('archive/legacy_runs/lr_estimation_2025_07_21/'\n",
    "#             'LRs for 87 features within GI ddx - dysphagia vs esophageal pain without dysphagia_filled.xlsx')\n",
    "\n",
    "\n",
    "#WB_IN  = Path('archive/legacy_runs/lr_estimation_2025_07_21/'\n",
    "#              'LRs for 87 features within esophageal dysphagia ddx - nonprogressive vs progressive.xlsx')\n",
    "\n",
    "#WB_OUT = Path('archive/legacy_runs/lr_estimation_2025_07_21/'\n",
    "#              'LRs for 87 features within esophageal dysphagia ddx - nonprogressive vs progressive_filled.xlsx')\n",
    "\n",
    "WB_IN  = Path('archive/legacy_runs/lr_estimation_2025_07_21/'\n",
    "              'LRs for 87 features within esoph dysmotility non-progressive dysphgia ddx - w or wo autoimmune.xlsx')\n",
    "\n",
    "WB_OUT = Path('archive/legacy_runs/lr_estimation_2025_07_21/'\n",
    "              'LRs for 87 features within esoph dysmotility non-progressive dysphgia ddx - w or wo autoimmune_filled.xlsx')\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# 5) Main sheet logic\n",
    "# =============================================================================\n",
    "\n",
    "# Load diagnostic categories & exemplars (rows 0–1)\n",
    "dx_cat_1, dx_cat_2, ex1, ex2 = load_dx_categories(WB_IN)\n",
    "\n",
    "# Read sheet and append results column (ensure object dtype to avoid warnings)\n",
    "df     = pd.read_excel(WB_IN, sheet_name=0, header=None)\n",
    "df_out = df.copy()\n",
    "\n",
    "result_col = df_out.shape[1]\n",
    "df_out[result_col] = pd.Series([None] * len(df_out), dtype=\"object\")\n",
    "\n",
    "header_label = f\"Differential LR ({MODEL_ID} for '{dx_cat_1}' vs. '{dx_cat_2}')\"\n",
    "df_out.iat[0, result_col] = header_label\n",
    "df_out.iat[1, result_col] = \"\"  # keep exemplar row blank\n",
    "\n",
    "# Iterate findings (rows ≥ 2) with progress\n",
    "total_rows = df_out.shape[0] - 2\n",
    "done = 0\n",
    "\n",
    "for row in range(2, df_out.shape[0]):\n",
    "    finding = str(df_out.iat[row, 0]).strip()\n",
    "    if not finding:\n",
    "        continue\n",
    "\n",
    "    done += 1\n",
    "    print(f\"[{done}/{total_rows}] Estimating LR for: {finding[:60]}\")\n",
    "\n",
    "    lr_val = estimate_diff_lr(\n",
    "        finding=finding,\n",
    "        dx_cat_1=dx_cat_1,\n",
    "        dx_cat_2=dx_cat_2,\n",
    "        ex1=ex1,\n",
    "        ex2=ex2,\n",
    "    )\n",
    "    df_out.iat[row, result_col] = lr_val\n",
    "\n",
    "# Save\n",
    "df_out.to_excel(WB_OUT, index=False, header=False)\n",
    "print(f\"\\nCompleted. Filled sheet saved to {WB_OUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04673eb0",
   "metadata": {},
   "source": [
    "## Supporting functions\n",
    "\n",
    "#### LR Estimate comparisons betwee models\n",
    "\n",
    "this script takes estimates from different model calls to be compared - doesn't consider the exact predictions (ie not paired differences) but just the overall distributions. \n",
    "\n",
    "columsn should be labeled and in a spreadsheet called columns_to_plot.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d78dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FixedLocator, FixedFormatter\n",
    "from scipy.stats import gaussian_kde\n",
    "from pathlib import Path\n",
    "\n",
    "def plot_multi_lr_kde(\n",
    "    excel_path: str | Path,\n",
    "    sheet: int | str = 0,\n",
    "    header_row: int = 0,\n",
    "    data_start_row: int = 1,\n",
    "    header_contains: str = r\"\\bLR\\b\",   # regex; case-insensitive\n",
    "    low: float = 1/32,\n",
    "    high: float = 32,\n",
    "    n_grid: int = 700,\n",
    "    bw_method: str | float = \"scott\",\n",
    "    min_points: int = 5,\n",
    "    alpha_bands: float = 0.12,\n",
    "    legend_loc: str = \"upper center\",\n",
    "    legend_ncol: int = 3,\n",
    "    figsize=(7.0, 4.0),\n",
    "    savepath: str | Path | None = \"columns_to_plot_kde_overlay.pdf\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Overlay KDEs (per log unit) for all columns whose first-row label matches `header_contains`.\n",
    "    Assumes the data cells in those columns are *LR values* (>0). NaNs & non-positive values are ignored.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    excel_path : path to workbook (e.g., 'columns_to_plot.xlsx')\n",
    "    sheet      : sheet index or name\n",
    "    header_row : row index containing column labels (default 0)\n",
    "    data_start_row : first row index containing numeric LR data (default 1)\n",
    "    header_contains : regex that selects columns by header (default: contains 'LR')\n",
    "    low, high  : x-range (LR scale), symmetric in log space (default 1/32..32)\n",
    "    n_grid     : number of x-grid points in log space\n",
    "    bw_method  : gaussian_kde bandwidth ('scott' | 'silverman' | float)\n",
    "    min_points : minimum non-NaN values required to draw a KDE for a column\n",
    "    alpha_bands: alpha for qualitative band shading\n",
    "    legend_loc : legend location\n",
    "    legend_ncol: legend columns\n",
    "    figsize    : figure size\n",
    "    savepath   : file path to save PDF/PNG; set None to skip saving\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig, ax\n",
    "    \"\"\"\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Read sheet exactly as laid out (no header inference)\n",
    "    df = pd.read_excel(excel_path, sheet_name=sheet, header=None)\n",
    "\n",
    "    # Identify candidate columns by header regex\n",
    "    headers = df.iloc[header_row].astype(str)\n",
    "    mask = headers.str.contains(header_contains, case=True, regex=True)\n",
    "    cols = np.flatnonzero(mask.values)\n",
    "\n",
    "    if len(cols) == 0:\n",
    "        raise ValueError(\"No columns found whose first-row label matches the regex for 'LR'.\")\n",
    "\n",
    "    # Matplotlib style: clean spines, readable font\n",
    "    plt.rcParams.update({\n",
    "        \"font.size\": 11,\n",
    "        \"axes.spines.right\": False,\n",
    "        \"axes.spines.top\": False\n",
    "    })\n",
    "\n",
    "    # Prebuild x-grid in log10 space; density is per log10 unit (labelled 'per log unit')\n",
    "    x_log = np.linspace(np.log10(low), np.log10(high), n_grid)\n",
    "    lr_x  = 10**x_log\n",
    "\n",
    "    # Qualitative bands (neg/pos strength)\n",
    "    cuts = [0.1, 0.2, 0.5, 2, 5, 10]\n",
    "    bands = [(low, 0.1), (0.1, 0.2), (0.2, 0.5), (0.5, 2), (2, 5), (5, 10), (10, high)]\n",
    "    light = \"#fde0dd\"; mid = \"#fa9fb5\"; dark = \"#c51b8a\"\n",
    "    band_cols = [dark, mid, light, \"#f0f0f0\", light, mid, dark]\n",
    "\n",
    "    # Color cycle for multiple curves\n",
    "    prop_cycle = plt.rcParams[\"axes.prop_cycle\"]\n",
    "    colors = prop_cycle.by_key().get(\"color\", [\"#0868ac\", \"#dd3497\", \"#41ab5d\", \"#e08214\", \"#756bb1\", \"#7b8b8e\"])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Shaded qualitative bands\n",
    "    for (a, b), col in zip(bands, band_cols):\n",
    "        ax.axvspan(a, b, color=col, alpha=alpha_bands, lw=0)\n",
    "\n",
    "    # Iterate columns; compute KDE in log10-space; normalise per log unit\n",
    "    plotted = 0\n",
    "    for i, col in enumerate(cols):\n",
    "        label = str(headers.iloc[col]).strip()\n",
    "\n",
    "        # Coerce to numeric; use only strictly positive values (LR > 0)\n",
    "        vals = pd.to_numeric(df.iloc[data_start_row:, col], errors=\"coerce\")\n",
    "        vals = vals[np.isfinite(vals)]\n",
    "        vals = vals[vals > 0]\n",
    "\n",
    "        if vals.size < min_points:\n",
    "            # Too few points for a stable KDE — skip\n",
    "            print(f\"Skipping '{label}' (n={vals.size} < {min_points}).\")\n",
    "            continue\n",
    "\n",
    "        log_vals = np.log10(vals.values)\n",
    "        kde = gaussian_kde(log_vals, bw_method=bw_method)\n",
    "        pdf = kde(x_log)\n",
    "        # Normalise so area under pdf over x_log equals 1 (per log unit)\n",
    "        area = np.trapz(pdf, x_log)\n",
    "        if area > 0:\n",
    "            pdf = pdf / area\n",
    "\n",
    "        ax.plot(lr_x, pdf, lw=2.0, label=label, color=colors[i % len(colors)])\n",
    "        plotted += 1\n",
    "\n",
    "    if plotted == 0:\n",
    "        raise ValueError(\"No columns had enough positive numeric values to plot.\")\n",
    "\n",
    "    # Log-scale x, fractional ticks\n",
    "    ticks = [1/32, 1/16, 1/8, 1/4, 1/2, 1, 2, 4, 8, 16, 32]\n",
    "    def frac_label(t: float) -> str:\n",
    "        return f\"1/{int(round(1/t))}\" if t < 1 else f\"{int(t)}\"\n",
    "    tick_labels = [frac_label(t) for t in ticks]\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xlim(low, high)\n",
    "    ax.set_xlabel(\"Likelihood ratio\")\n",
    "    ax.set_ylabel(\"Density (per log unit)\")\n",
    "\n",
    "    ax.xaxis.set_major_locator(FixedLocator(ticks))\n",
    "    ax.xaxis.set_major_formatter(FixedFormatter(tick_labels))\n",
    "\n",
    "    # Reference lines at band cutoffs\n",
    "    for c in cuts:\n",
    "        ax.axvline(c, ls=\"--\", lw=0.7, color=\"grey\")\n",
    "\n",
    "    ax.grid(which=\"major\", ls=\"--\", lw=0.4, alpha=0.5)\n",
    "    ax.grid(which=\"minor\", lw=0, alpha=0)\n",
    "\n",
    "    # Legend\n",
    "    ax.legend(loc=legend_loc, ncol=legend_ncol, frameon=False)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if savepath is not None:\n",
    "        savepath = Path(savepath)\n",
    "        fig.savefig(savepath, dpi=600, bbox_inches=\"tight\")\n",
    "        print(f\"Saved figure to {savepath}\")\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "# Example call (same folder as your spreadsheet)\n",
    "fig, ax = plot_multi_lr_kde(Path('archive/legacy_runs/lr_estimation_2025_07_21/columns_to_plot.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c3883e",
   "metadata": {},
   "source": [
    "#### Bland Altman Plots for agreement of the same tspreadsheet columns\n",
    "\n",
    "all the pairwise combinations that start with LR\n",
    "\n",
    "\t•\tReads an Excel sheet.\n",
    "\t•\tSelects all columns whose first-row header contains “LR” (regex, case-insensitive).\n",
    "\t•\tDetects whether the data are raw LR or log-LR (auto, overrideable).\n",
    "\t•\tGenerates a separate multiplicative (x-fold) Bland–Altman plot for every pairwise comparison among the selected columns.\n",
    "\t•\tAnnotates mean bias and 95% LoA in ×-fold units.\n",
    "\t•\tUses shared axis limits across all pairs for comparability.\n",
    "\t•\tSaves one PDF per pair under ba_pair_plots/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049bd6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib.transforms import blended_transform_factory\n",
    "\n",
    "# Optional: Pingouin for built-in BA panel. We fall back to manual if missing.\n",
    "try:\n",
    "    import pingouin as pg\n",
    "    _HAS_PG = True\n",
    "except Exception:\n",
    "    _HAS_PG = False\n",
    "\n",
    "\n",
    "def _sanitize(name: str) -> str:\n",
    "    \"\"\"Safe string for filenames.\"\"\"\n",
    "    s = re.sub(r\"\\s+\", \"_\", str(name).strip())\n",
    "    s = re.sub(r\"[^A-Za-z0-9_.-]\", \"\", s)\n",
    "    return s[:120]\n",
    "\n",
    "\n",
    "def plot_pairwise_ba_from_excel(\n",
    "    excel_path: str | Path,\n",
    "    sheet: int | str = 0,\n",
    "    header_row: int = 0,\n",
    "    data_start_row: int = 1,\n",
    "    header_regex: str = r\"LR\",        # select columns whose header contains 'LR'\n",
    "    assume_scale: str = \"auto\",       # 'auto' | 'lr' | 'ln'\n",
    "    outdir: str | Path = \"ba_pair_plots\",\n",
    "    point_kwargs: dict | None = None, # e.g. {\"s\": 15, \"alpha\": 0.7, \"color\": \"#1b8e5a\"}\n",
    "    line_kwargs: dict | None = None,  # e.g. {\"color\": \"black\", \"lw\": 1.1}\n",
    "    style_science: bool = True,       # try to use SciencePlots if available\n",
    ") -> list[Path]:\n",
    "    \"\"\"\n",
    "    Create one Bland–Altman plot per pair of selected columns (multiplicative, x-fold).\n",
    "    Y-axis = ln-ratio (formatted as ×-fold). X-axis = mean ln (formatted as LR).\n",
    "    \"\"\"\n",
    "\n",
    "    # --- style ---------------------------------------------------------------\n",
    "    if style_science:\n",
    "        try:\n",
    "            plt.style.use([\"science\", \"no-latex\"])\n",
    "        except Exception:\n",
    "            pass\n",
    "    plt.rcParams.update({\"axes.spines.top\": False, \"axes.spines.right\": False})\n",
    "\n",
    "    # --- read & select columns ----------------------------------------------\n",
    "    excel_path = Path(excel_path)\n",
    "    df = pd.read_excel(excel_path, sheet_name=sheet, header=None)\n",
    "\n",
    "    headers = df.iloc[header_row].astype(str)\n",
    "    sel = headers[headers.str.contains(header_regex, case=True, regex=True)]\n",
    "    if sel.empty:\n",
    "        raise ValueError(\"No columns matched header_regex; nothing to compare.\")\n",
    "\n",
    "    # Build dict: label -> numeric series\n",
    "    series_dict: dict[str, pd.Series] = {}\n",
    "    for col_idx, label in sel.items():\n",
    "        s = pd.to_numeric(df.iloc[data_start_row:, col_idx], errors=\"coerce\")\n",
    "        series_dict[str(label).strip()] = s\n",
    "\n",
    "    labels = list(series_dict.keys())\n",
    "    if len(labels) < 2:\n",
    "        raise ValueError(\"Need ≥2 matching columns to run pairwise BA comparisons.\")\n",
    "\n",
    "    # --- scale detection (LR vs ln-LR) ---------------------------------------\n",
    "    def _contains_log_hint(names: list[str]) -> bool:\n",
    "        pat = re.compile(r\"\\b(ln|log)\\b\", re.IGNORECASE)\n",
    "        return any(pat.search(n) for n in names)\n",
    "\n",
    "    if assume_scale not in {\"auto\", \"lr\", \"ln\"}:\n",
    "        raise ValueError(\"assume_scale must be 'auto', 'lr', or 'ln'.\")\n",
    "\n",
    "    if assume_scale == \"ln\":\n",
    "        as_log = True\n",
    "    elif assume_scale == \"lr\":\n",
    "        as_log = False\n",
    "    else:\n",
    "        # auto: header hint first, else non-positivity\n",
    "        if _contains_log_hint(labels):\n",
    "            as_log = True\n",
    "        else:\n",
    "            # If any column has any non-positive value, treat as ln (LR cannot be <= 0)\n",
    "            any_nonpos = any((s.fillna(np.nan) <= 0).any() for s in series_dict.values())\n",
    "            as_log = any_nonpos\n",
    "\n",
    "    # --- helper formatters ---------------------------------------------------\n",
    "    def fmt_exp(x, _):  # display LR values on ln axis\n",
    "        return f\"{np.exp(x):.2g}\"\n",
    "    x_fmt = FuncFormatter(fmt_exp)\n",
    "\n",
    "    def fmt_fold(x, _):  # display ×-fold on ln-diff axis\n",
    "        return f\"{np.exp(x):.2g}×\"\n",
    "    y_fmt = FuncFormatter(fmt_fold)\n",
    "\n",
    "    # --- build ln-series and collect global limits ---------------------------\n",
    "    ln_data = {}\n",
    "    for lab, s in series_dict.items():\n",
    "        s = s.astype(float)\n",
    "        if as_log:\n",
    "            ln_data[lab] = s.replace([np.inf, -np.inf], np.nan)\n",
    "        else:\n",
    "            # raw LR → ln\n",
    "            s = s.where(s > 0, np.nan)\n",
    "            ln_data[lab] = np.log(s)\n",
    "\n",
    "    # Global limits over all pairwise combos\n",
    "    means_all, diffs_all = [], []\n",
    "    pairs = list(itertools.combinations(labels, 2))\n",
    "    for a, b in pairs:\n",
    "        A, B = ln_data[a], ln_data[b]\n",
    "        ok = A.notna() & B.notna()\n",
    "        if ok.sum() < 3:\n",
    "            continue\n",
    "        m = (A[ok] + B[ok]) / 2\n",
    "        d = (A[ok] - B[ok])\n",
    "        means_all.append(m.values)\n",
    "        diffs_all.append(d.values)\n",
    "\n",
    "    if not means_all:\n",
    "        raise ValueError(\"No pair had ≥3 overlapping rows after NaN filtering.\")\n",
    "\n",
    "    means_all = np.concatenate(means_all)\n",
    "    diffs_all = np.concatenate(diffs_all)\n",
    "    xlim = (means_all.min(), means_all.max())\n",
    "    ylim = (-1.1 * np.abs(diffs_all).max(), 1.1 * np.abs(diffs_all).max())\n",
    "\n",
    "    # --- default aesthetics --------------------------------------------------\n",
    "    if point_kwargs is None:\n",
    "        point_kwargs = {\"s\": 18, \"alpha\": 0.7}\n",
    "    if line_kwargs is None:\n",
    "        line_kwargs = {\"color\": \"black\", \"lw\": 1.1}\n",
    "\n",
    "    outdir = Path(outdir)\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    saved: list[Path] = []\n",
    "\n",
    "    # --- plot each pair ------------------------------------------------------\n",
    "    for a, b in pairs:\n",
    "        A, B = ln_data[a], ln_data[b]\n",
    "        ok = A.notna() & B.notna()\n",
    "        if ok.sum() < 3:\n",
    "            print(f\"Skip: '{a}' vs '{b}' (n={ok.sum()} < 3).\")\n",
    "            continue\n",
    "\n",
    "        x = ((A[ok] + B[ok]) / 2).values  # ln geometric mean\n",
    "        y = (A[ok] - B[ok]).values        # ln ratio A/B\n",
    "\n",
    "        mu = y.mean()\n",
    "        sd = y.std(ddof=1)\n",
    "        loa_hi = mu + 1.96 * sd\n",
    "        loa_lo = mu - 1.96 * sd\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(5.6, 4.0))\n",
    "\n",
    "        if _HAS_PG:\n",
    "            # Pingouin BA adds lines; we will re-style them and re-annotate\n",
    "            pg.plot_blandaltman(A[ok].values, B[ok].values, ax=ax,\n",
    "                                marker=\"o\", **{k:v for k,v in point_kwargs.items() if k in {\"s\",\"alpha\",\"color\"}})\n",
    "            # mean line then LoA lines:\n",
    "            ax.lines[0].set(**line_kwargs)  # mean\n",
    "            for ln in ax.lines[1:]:\n",
    "                ln.set(linestyle=\"--\", **line_kwargs)\n",
    "        else:\n",
    "            # Manual BA\n",
    "            ax.scatter(x, y, marker=\"o\", **point_kwargs)\n",
    "            ax.axhline(mu, **line_kwargs)\n",
    "            ax.axhline(loa_hi, linestyle=\"--\", **line_kwargs)\n",
    "            ax.axhline(loa_lo, linestyle=\"--\", **line_kwargs)\n",
    "\n",
    "        # remove any auto text (from pg)\n",
    "        for t in list(ax.texts):\n",
    "            t.remove()\n",
    "\n",
    "        # right-side labels in ×-fold\n",
    "        trans = blended_transform_factory(ax.transAxes, ax.transData)\n",
    "        ax.text(0.98, mu,     f\"Mean: {np.exp(mu):.2f}×\",\n",
    "                transform=trans, ha=\"right\", va=\"center\", fontsize=11)\n",
    "        ax.text(0.98, loa_hi, f\"95% LoA: {np.exp(loa_hi):.2f}×\",\n",
    "                transform=trans, ha=\"right\", va=\"bottom\", fontsize=11)\n",
    "        ax.text(0.98, loa_lo, f\"95% LoA: {np.exp(loa_lo):.2f}×\",\n",
    "                transform=trans, ha=\"right\", va=\"top\", fontsize=11)\n",
    "\n",
    "        # axes formatting (ln space; label as LR and ×-fold)\n",
    "        ax.set_xlim(xlim); ax.set_ylim(ylim)\n",
    "        ax.xaxis.set_major_formatter(x_fmt)\n",
    "        ax.yaxis.set_major_formatter(y_fmt)\n",
    "\n",
    "        ax.set_title(f\"{a} vs {b}\", fontsize=13)\n",
    "        ax.set_xlabel(\"Geometric mean LR\", fontsize=12)\n",
    "        ax.set_ylabel(f\"LR ratio ({a} / {b})\", fontsize=12)\n",
    "\n",
    "        fig.tight_layout()\n",
    "\n",
    "        fname = outdir / f\"ba_{_sanitize(a)}__vs__{_sanitize(b)}.pdf\"\n",
    "        fig.savefig(fname, format=\"pdf\", bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        print(f\"Saved: {fname}\")\n",
    "        saved.append(fname)\n",
    "\n",
    "    return saved\n",
    "\n",
    "# Example: columns whose first-row header contains 'LR'\n",
    "files = plot_pairwise_ba_from_excel(\n",
    "    Path('archive/legacy_runs/lr_estimation_2025_07_21/columns_to_plot.xlsx'),\n",
    "    header_regex=r\"LR\",        # select headers that contain 'LR'\n",
    "    assume_scale=\"auto\",       # or 'lr' if raw LRs, 'ln' if log-LRs\n",
    "    outdir=Path('archive/legacy_runs/lr_estimation_2025_07_21/')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
