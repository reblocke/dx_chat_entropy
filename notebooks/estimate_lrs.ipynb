{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repository setup for portable, repo-relative paths\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "def _find_repo_root(start: Path | None = None) -> Path:\n",
    "    start = (start or Path.cwd()).resolve()\n",
    "    for candidate in [start, *start.parents]:\n",
    "        if (candidate / \"pyproject.toml\").exists():\n",
    "            return candidate\n",
    "    return start\n",
    "\n",
    "REPO_ROOT = _find_repo_root()\n",
    "if str(REPO_ROOT / \"src\") not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT / \"src\"))\n",
    "\n",
    "from dx_chat_entropy.paths import get_paths\n",
    "PATHS = get_paths(REPO_ROOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workbook is used to estimate the likelihood ratios for features (e.g. info from the HPI, exam findings) that haven't been reported in the literature yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from markitdown import MarkItDown\n",
    "import llm\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "import os\n",
    "from typing import List, Optional, Literal\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # looks for a .env file in the current dir by default\n",
    "#print(os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "ASSESSMENT_DIR = str(PATHS.processed / 'assessments')\n",
    "ASSESSMENT_TEMPLATE = str(PATHS.raw / 'assessment_templates' / 'asssessment_template_new.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing of the specification for what assessments we want the LLM to look for\n",
    "\n",
    "def process_sheet(sheet_data):\n",
    "    \"\"\"\n",
    "    Processes a sheet to extract the 'Information' and associated 'LR' values.\n",
    "    Ignores the 'Y/N' column.\n",
    "    Returns a list of tuples (information_str, lr_value).\n",
    "    \"\"\"\n",
    "    # Drop Y/N column if it exists\n",
    "    sheet_data = sheet_data.drop(columns=[\"Y/N\"], errors=\"ignore\")\n",
    "\n",
    "    info_list = []\n",
    "\n",
    "    # Iterate through each row and capture the single 'Information' + 'LR' from that row\n",
    "    for _, row in sheet_data.iterrows():\n",
    "        info_val = row.get(\"Information\", None)  # Safely get 'Information' column\n",
    "        lr_val = row.get(\"LR\", None)             # Safely get 'LR' column\n",
    "\n",
    "        # If the information cell is not empty/NaN, we record it.\n",
    "        # If LR is NaN or missing, we'll store it as None.\n",
    "        if pd.notnull(info_val):\n",
    "            # Normalize LR to None if it's NaN\n",
    "            if pd.isnull(lr_val):\n",
    "                lr_val = None\n",
    "\n",
    "            info_list.append((info_val, lr_val))\n",
    "\n",
    "    return info_list\n",
    "\n",
    "diagnosis_info = {}\n",
    "with pd.ExcelFile(ASSESSMENT_TEMPLATE) as spreadsheet_data:\n",
    "    for sheet_name in spreadsheet_data.sheet_names:\n",
    "        try:\n",
    "            sheet_data = pd.read_excel(ASSESSMENT_TEMPLATE, sheet_name=sheet_name)\n",
    "\n",
    "            if sheet_data.empty:\n",
    "                print(f\"Skipping empty sheet: {sheet_name}\")\n",
    "                continue\n",
    "\n",
    "            # Process the sheet to get [(info, LR), ...]\n",
    "            diagnosis_info[sheet_name] = process_sheet(sheet_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sheet '{sheet_name}': {e}\")\n",
    "\n",
    "# Print out the collected data\n",
    "for diagnosis, info_pairs in diagnosis_info.items():\n",
    "    print(f\"Diagnosis: {diagnosis}\")\n",
    "    for info_val, lr_val in info_pairs:\n",
    "        print(f\"  Information: {info_val}, LR: {lr_val}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# ESTIMATE LRS FOR ALL THAT HAVE UNKNOWN LRS\n",
    "# TODO: Note, in the real workflow - should do this using o1 and only do it once, rather than over and over.\n",
    "\n",
    "class LRResponse(BaseModel):\n",
    "    \"\"\"\n",
    "    A structured schema ensuring the model returns exactly one of the five LR labels.\n",
    "    \"\"\"\n",
    "    label: Literal[\"STRONG NEGATIVE\", \n",
    "                   \"WEAK NEGATIVE\", \n",
    "                   \"NEUTRAL\", \n",
    "                   \"WEAK POSITIVE\", \n",
    "                   \"STRONG POSITIVE\"]\n",
    "\n",
    "\n",
    "def estimate_lr(diagnosis, info_val, client):\n",
    "    \"\"\"\n",
    "    Returns one of the five LR categories (STRONG NEGATIVE, WEAK NEGATIVE,\n",
    "    NEUTRAL, WEAK POSITIVE, STRONG POSITIVE) for a given diagnosis and info_val.\n",
    "    Uses OpenAI's structured output parsing to ensure the response is valid.\n",
    "    \"\"\"\n",
    "\n",
    "    lr_prompt = \"\"\"You are an expert diagnostician who is explaining to a trainee which pieces of information they should pay attention to during the diagnostic process. Your task is to summarize how strong of evidence the presence or absence of a particular new finding is for whether a patient has a disease. For example, if a patient has chest pain and the EKG show ST segment elevations, this is STRONG evidence that the chest pain is due to a heart attack. If the patient has t-wave inversions, this is WEAKER evidence in favor - because t-wave changes are not as specific for cardiac causes of chest pain. If they have known heartburn, this is WEAK absence against (because it’s an explanation, but it IS possible to have a history of heartburn but have a heart attack). Lastly, if they are a young female without an inherited condition, this is STRONG evidence against a cardiac cause because that demographic almost never has heart attacks. Lastly, if the piece of information is unhelpful, it would be called neutral. For example, if the patient has blue eyes irrelevant to the cause of chest pain, thus it would be NEUTRAL. \n",
    "\n",
    "    I’d like you to follow the following steps:\n",
    "        1.\tConsider, what does the finding mean about what is going on with the patient?\n",
    "        2.\tdoes the presence of the new information make the disease more or less likely? Or no difference?\n",
    "        3.\tDoes the finding make another cause of the same symptom more common? If so, then by definition it makes the target condition a less likely explanation.\n",
    "        4.\tOnce you’ve decided whether the finding makes the diagnosis more or less likely, use the following scale to come up with a response:\n",
    "\n",
    "        •\tIf knowing the piece of information makes the odds of the diagnosis more than 1.95x higher than it was before, it is a STRONG POSITIVE finding\n",
    "        •\tIf knowing the piece of information makes the odds of the diagnosis 1.18x to 1.95x higher than it was before, it is a WEAK POSITIVE finding\n",
    "        •\tIf knowing the piece of information makes changes the odds only 0.92x to 1.18x as likely as it was before, then it is a NEUTRAL finding\n",
    "        •\tIf knowing the piece of information makes the odds of the diagnosis 0.72x to 0.92x times as likely as it was before, then it is a WEAK NEGATIVE finding.\n",
    "        •\tIf knowing the piece of information makes the odds of the diagnosis less than 0.72x higher than it was before, it is a STRONG POSITIVE\n",
    "\n",
    "    As another example, say I’m wondering whether a patient with GI bleeding has a lower GI bleed (below the ligament of Treitz) or an upper GI bleed. The presence of clots in the blood is a very strong predictor of lower GI bleeding, because bleeding from the stomach cannot form clots due to the stomach acid. You should use all physiologic clues to whether a piece of information is a STRONG, WEAK, or NEUTRAL predictor. \n",
    "\n",
    "    You will receive inputs in the following format; Target condition: <Condition, e.g. Cardiac chest pain>. Finding: <piece of information, e.g. ‘No radiation to the neck, arm, or jaw’>.\n",
    "\n",
    "    You must respond with EXACTLY ONE of the following categories (no extra text):\n",
    "    STRONG POSITIVE, WEAK POSITIVE, NEUTRAL, WEAK NEGATIVE, STRONG NEGATIVE.\n",
    "\n",
    "    You must respond with EXACTLY one of these categories in valid JSON\n",
    "    Your output must match the Pydantic schema: { 'label': '<one of the five strings>' }\n",
    "\n",
    "    Here are some examples:\n",
    "    Prompt = Target condition: Cardiac Chest Pain. Finding: Pain not worse with exertion (requires they clarify exercise 1hr after meal).\n",
    "    You would reason that because cardiac chest pain is usually worse with exertion because exertion worsens cardiac demand for oxygen, and thus worsens ischemia.\n",
    "    Response = {\n",
    "        \"label\": \"STRONG NEGATIVE\"\n",
    "    }\n",
    "\n",
    "    Prompt =  Target condition: Cardiac Chest Pain. Finding: No tobacco.\n",
    "    You would reason that because being someone who smokes increases your risk of coronary artery disease, and thus being a never smoker means you’re at less risk… but many people who have heart attacks still smoke, so it’s only a weak predictor. \n",
    "    Response = {\n",
    "        \"label\": \"WEAK NEGATIVE\"\n",
    "    }\n",
    "\n",
    "    Prompt = Target condition: Cardaic Chest Pain. Finding = enjoys playing chess.\n",
    "    You would reason that because enjoying chest has no relationship to having a heart attack.\n",
    "    Response = {\n",
    "        \"label\": \"NEUTRAL\"\n",
    "    }\n",
    "\n",
    "    Prompt = Target condition: Cardiac Chest Pain. Finding = pain located behind the sternum\n",
    "    You would reason that because cardiac chest pain is often experienced behind the sternum (thus, more likely), but so are many other causes of chest pain - like GERD.\n",
    "    Response = {\n",
    "        \"label\": \"WEAK POSITIVE\"\n",
    "    }\n",
    "\n",
    "    Prompt = Condition: Cardiac Chest Pain. Finding = pain worse with exertion.\n",
    "    You would reason that because the increased myocardial oxygen consumption worsens the pain if oxygen delivery to the myocardium is the cause, as it is in heart attacks.\n",
    "    Response = {\n",
    "        \"label\": \"STRONG NEGATIVE\"\n",
    "    }\n",
    "\n",
    "    OK: here’s the prompt…. \"\"\"\n",
    "        \n",
    "    # Create your conversation messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": lr_prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Condition: {diagnosis}\\nFinding: {info_val}\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Make the structured call to the model\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        response_format=LRResponse,  # Our Pydantic model\n",
    "    )\n",
    "    \n",
    "    # Extract the parsed LRResponse from the completion\n",
    "    lr_response = completion.choices[0].message.parsed  # This will be an LRResponse instance\n",
    "    # The label is guaranteed to be one of the enumerated strings by Pydantic\n",
    "    return lr_response.label\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "for diagnosis, info_pairs in diagnosis_info.items():\n",
    "    # info_pairs is a list of (info_val, lr_val) tuples\n",
    "    for idx, (info_val, lr_val) in enumerate(info_pairs):\n",
    "        if lr_val is None:  # Missing LR\n",
    "            estimated_label = estimate_lr(diagnosis, info_val, client)\n",
    "            # Update the tuple\n",
    "            info_pairs[idx] = (info_val, estimated_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(ASSESSMENT_DIR, \"completed_lrs.xlsx\")\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "    for diagnosis, info_pairs in diagnosis_info.items():\n",
    "        # Convert list of (info, lr) tuples into a DataFrame\n",
    "        data = [{\"Information\": info_val, \"LR\": lr_val} for info_val, lr_val in info_pairs]\n",
    "        df = pd.DataFrame(data, columns=[\"Information\", \"LR\"])\n",
    "        \n",
    "        # Write each diagnosis to a separate sheet\n",
    "        # (sheet_name must be <= 31 chars in Excel)\n",
    "        sheet_name = str(diagnosis)[:31]\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"Excel file saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
